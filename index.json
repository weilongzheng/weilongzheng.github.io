[{"authors":null,"categories":null,"content":"Hi, I am currently a Postdoc Associate in Department of Brain and Cognitive Science at Massachusetts Institute of Technology (MIT). I work with Michael Halassa and Robert Yang on developing computational models for thalamocortical interactions in cognition. My research interests cover the broad areas of computational neuroscience, machine learning, AI, clinical healthcare, biomedical engineering, and cognition.\nPrior to MIT, I was a research fellow in Department of Neurology, Massachusetts General Hospital, Harvard Medical School, working with M Brandon Westover, MD, PhD. I obtained my PhD degree in the Center for Brain-Like Computing and Machine Intelligence, Department of Computer Science, Shanghai Jiao Tong University (2012-2018), China, supervised by Bao-Liang Lu. I obtained my Bachelor degree from Talented Student Program in Department of Electronic and Information Engineering, South China University of Technology, China, in 2012.\nFrom 06/2016 - 09/2016, I was a visiting researcher in The Cichocki Laboratory for Advanced Brain Signal Processing, Brain Science Institute, RIKEN, Japan. From 09/2014 - 03/2015, I was a visiting researcher in Intelligent Systems Group, Department of Computer Science and Artificial Intelligence, University of the Basque Country, Spain.\n","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":-62135596800,"objectID":"598b63dd58b43bce02403646f240cd3c","permalink":"https://weilongzheng.github.io/author/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/admin/","section":"author","summary":"Hi, I am currently a Postdoc Associate in Department of Brain and Cognitive Science at Massachusetts Institute of Technology (MIT). I work with Michael Halassa and Robert Yang on developing computational models for thalamocortical interactions in cognition. My research interests cover the broad areas of computational neuroscience, machine learning, AI, clinical healthcare, biomedical engineering, and cognition.\nPrior to MIT, I was a research fellow in Department of Neurology, Massachusetts General Hospital, Harvard Medical School, working with M Brandon Westover, MD, PhD.","tags":null,"title":"","type":"author"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":-62135596800,"objectID":"d41d8cd98f00b204e9800998ecf8427e","permalink":"https://weilongzheng.github.io/author/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/","section":"author","summary":"","tags":null,"title":"Authors","type":"author"},{"authors":null,"categories":null,"content":"","date":1617249600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1617249600,"objectID":"b5212ff14495335aecc0bf56f04a5957","permalink":"https://weilongzheng.github.io/project/thalamus/","publishdate":"2021-04-01T00:00:00-04:00","relpermalink":"/project/thalamus/","section":"project","summary":"Develop recurrent neural networks with a thalamus-like component and synaptic plasticity rules to model the thalamocortical interactions in cognitive flexibility.","tags":[],"title":"Building and Understanding the Brain","type":"project"},{"authors":null,"categories":null,"content":"","date":1609477200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609477200,"objectID":"e0620b5b2691eeabd7ec4c8d4c8a81f2","permalink":"https://weilongzheng.github.io/project/neurophysiology/","publishdate":"2021-01-01T00:00:00-05:00","relpermalink":"/project/neurophysiology/","section":"project","summary":"Continuous brain monitoring to identify neural dynamics and predict neuological outcomes for critically ill patients.","tags":[],"title":"Critical Care Neurophysiology","type":"project"},{"authors":["Junwu Weng","Xudong Jiang","**Wei-Long Zheng**","Junsong Yuan"],"categories":null,"content":"","date":1582779600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1582779600,"objectID":"664722a1f0147ca9e6fd91c217d13e02","permalink":"https://weilongzheng.github.io/publication/weng2020early/","publishdate":"2020-02-27T00:00:00-05:00","relpermalink":"/publication/weng2020early/","section":"publication","summary":"The goal of early action recognition is to predict action label when the sequence is partially observed. The existing methods treat the early action recognition task as sequential classification problems on different observation ratios of an action sequence. Since these models are trained by differentiating positive category from all negative classes, the diverse information of different negative categories is ignored, which we believe can be collected to help improve the recognition performance. In this paper, we step towards to a new direction by introducing category exclusion to early action recognition. We model the exclusion as a mask operation on the classification probability output of a pre-trained early action recognition classifier. Specifically, we use policy-based reinforcement learning to train an agent. The agent generates a series of binary masks to exclude interfering negative categories during action execution and hence help improve the recognition accuracy. The proposed method is evaluated on three benchmark recognition datasets, NTU-RGBD, First-Person Hand Action, as well as UCF-101. The proposed method enhances the recognition accuracy consistently over all different observation ratios on the three datasets, where the accuracy improvements on the early stages are especially significant.","tags":[],"title":"Early Action Recognition with Category Exclusion using Policy-based Reinforcement Learning","type":"publication"},{"authors":["Amorim, Edilberto","Marcos Firme","**Wei-Long Zheng**","Kenneth Shelton","Oluwaseun Johnson-Akeju","Gaston Cudemus","Yuval Raz","M. Brandon Westover"],"categories":null,"content":"","date":1579064400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1579064400,"objectID":"e594e2a55a29f423ac8173585557dae7","permalink":"https://weilongzheng.github.io/publication/amorim2020767/","publishdate":"2020-01-15T00:00:00-05:00","relpermalink":"/publication/amorim2020767/","section":"publication","summary":"","tags":[],"title":"Epileptiform Abnormalities are Associated with Increased Mortality in Adult ECMO Patients","type":"publication"},{"authors":["**Wei-Long Zheng**","Jennifer Kim","Sahar Zafar","Eric Rosenthal","M. Brandon Westover"],"categories":null,"content":"","date":1579064400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1579064400,"objectID":"52dafd4be81273bedb60e3d29fabe7ec","permalink":"https://weilongzheng.github.io/publication/zheng2020760/","publishdate":"2020-01-15T00:00:00-05:00","relpermalink":"/publication/zheng2020760/","section":"publication","summary":"","tags":[],"title":"Machine Learning Model of EEG Trends Predicts Delayed Cerebral Ischemia Post-subarachnoid Hemorrhage","type":"publication"},{"authors":["Bo-Qun Ma","He Li","**Wei-Long Zheng**","Bao-Liang Lu"],"categories":null,"content":"","date":1575867600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1575867600,"objectID":"c2e717d0ec1fe28654d5ad656d31aa62","permalink":"https://weilongzheng.github.io/publication/ma2019reducing/","publishdate":"2019-12-09T00:00:00-05:00","relpermalink":"/publication/ma2019reducing/","section":"publication","summary":"","tags":[],"title":"Reducing the Subject Variability of EEG Signals with Adversarial Domain Generalization","type":"publication"},{"authors":["Jiaxin Ma","Hao Tang","**Wei-Long Zheng**","Bao-Liang Lu"],"categories":null,"content":"","date":1571716800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1571716800,"objectID":"3cb85efcc287e8e8dcb54084796cf3d0","permalink":"https://weilongzheng.github.io/publication/ma2019emotion/","publishdate":"2019-10-22T00:00:00-04:00","relpermalink":"/publication/ma2019emotion/","section":"publication","summary":"","tags":[],"title":"Emotion Recognition using Multimodal Residual LSTM Network","type":"publication"},{"authors":null,"categories":null,"content":"","date":1569902400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1569902400,"objectID":"1ce2dde4da6b4ea237172215f7bb2977","permalink":"https://weilongzheng.github.io/project/dci/","publishdate":"2019-10-01T00:00:00-04:00","relpermalink":"/project/dci/","section":"project","summary":"Predict delayed cerebral ischemia after subarachnoid hemorrhage with quantitative EEG.","tags":[],"title":"Delayed Cerebral Ischemia Prediction","type":"project"},{"authors":["**Wei-Long Zheng**","Haoqi Sun","Oluwaseun Akeju","M Brandon Westover"],"categories":null,"content":"","date":1569211200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1569211200,"objectID":"fcc7267ba91f9f7d152da54d9c9d38cd","permalink":"https://weilongzheng.github.io/publication/zheng2019adaptive/","publishdate":"2019-09-23T00:00:00-04:00","relpermalink":"/publication/zheng2019adaptive/","section":"publication","summary":"Sedative medications are routinely administered to provide comfort and facilitate clinical care in critically ill ICU patients. Prior work shows that brain monitoring using electroencephalography (EEG) to track sedation levels may help medical personnel to optimize drug dosing and avoid the adverse effects of oversedation and undersedation. However, the performance of sedation monitoring methods proposed to date deal poorly with individual variability across patients, leading to inconsistent performance. To address this challenge we develop an online learning approach based on Adaptive Regularization of Weight Vectors (AROW). Our approach adaptively updates a sedation level prediction algorithm under a continuously evolving data distribution. The prediction model is gradually calibrated for individual patients in response to EEG observations and routine clinical assessments over time. The evaluations are performed on a population of 172 sedated ICU patients whose sedation levels were assessed using the Richmond Agitation-Sedation Scale (scores between -5 = comatose and 0 = awake). The proposed adaptive model achieves better performance than the same model without adaptation (average accuracies with tolerance of one level difference: 68.76% vs. 61.10%). Moreover, our approach is shown to be robust to sudden changes caused by label noise. Medication administrations have different effects on model performance. We find that the model performs best in patients receiving only propofol, compared to patients receiving no sedation or multiple simultaneous sedative medications. ","tags":[],"title":"Adaptive Sedation Monitoring from EEG in ICU Patients with Online Learning","type":"publication"},{"authors":["Haoqi Sun","Eyal Kimchi","Oluwaseun Akeju","Sunil B. Nagaraj","Lauren M. McClain","David W. Zhou","Emily Boyle","**Wei-Long Zheng**","Wendong Ge","M. Brandon Westover"],"categories":null,"content":"","date":1568001600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1568001600,"objectID":"4ff0efd99200dc8760c3d8cd1930955d","permalink":"https://weilongzheng.github.io/publication/sun2019automated/","publishdate":"2019-09-09T00:00:00-04:00","relpermalink":"/publication/sun2019automated/","section":"publication","summary":"Over- and under-sedation are common in the ICU, and contribute to poor ICU outcomes including delirium. Behavioral assessments, such as Richmond Agitation-Sedation Scale (RASS) for monitoring levels of sedation and Confusion Assessment Method for the ICU (CAM-ICU) for detecting signs of delirium, are often used. As an alternative, brain monitoring with electroencephalography (EEG) has been proposed in the operating room, but is challenging to implement in ICU due to the differences between critical illness and elective surgery, as well as the duration of sedation. Here we present a deep learning model based on a combination of convolutional and recurrent neural networks that automatically tracks both the level of consciousness and delirium using frontal EEG signals in the ICU. For level of consciousness, the system achieves a median accuracy of 70% when allowing prediction to be within one RASS level difference across all patients, which is comparable or higher than the median technicianâ€“nurse agreement at 59%. For delirium, the system achieves an AUC of 0.80 with 69% sensitivity and 83% specificity at the optimal operating point. The results show it is feasible to continuously track level of consciousness and delirium in the ICU.","tags":[],"title":"Automated tracking of level of consciousness and delirium in critical illness using deep learning","type":"publication"},{"authors":["Wei Liu","Jie-Lin Qiu","**Wei-Long Zheng**","Bao-Liang Lu"],"categories":null,"content":"","date":1565668800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1565668800,"objectID":"3714da5edd6bdfd3daf9f5877d9db265","permalink":"https://weilongzheng.github.io/publication/liu2019multimodal/","publishdate":"2019-08-13T00:00:00-04:00","relpermalink":"/publication/liu2019multimodal/","section":"publication","summary":"","tags":[],"title":"Multimodal Emotion Recognition Using Deep Canonical Correlation Analysis","type":"publication"},{"authors":["Tian-Hao Li","Wei Liu","**Wei-Long Zheng**","Bao-Liang Lu"],"categories":null,"content":"","date":1558324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1558324800,"objectID":"4f632cd53d35cd6a17aed3506630ef38","permalink":"https://weilongzheng.github.io/publication/li2019classification/","publishdate":"2019-05-20T00:00:00-04:00","relpermalink":"/publication/li2019classification/","section":"publication","summary":"","tags":[],"title":"Classification of five emotions from EEG and eye movement signals: Discrimination ability and stability over time","type":"publication"},{"authors":["Li-Ming Zhao","Rui Li","Wei-Long Zheng","Bao-Liang Lu"],"categories":null,"content":"","date":1558324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1558324800,"objectID":"d7c1ee1ef830ab18bac028b9c2783b34","permalink":"https://weilongzheng.github.io/publication/zhao2019classification/","publishdate":"2019-05-20T00:00:00-04:00","relpermalink":"/publication/zhao2019classification/","section":"publication","summary":"","tags":[],"title":"Classification of five emotions from EEG and eye movement signals: complementary representation properties","type":"publication"},{"authors":["Xun Wu","**Wei-Long Zheng**","Bao-Liang Lu"],"categories":null,"content":"","date":1558324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1558324800,"objectID":"2899c2db092e69e0ab2ea11bb658a1f2","permalink":"https://weilongzheng.github.io/publication/wu2019identifying/","publishdate":"2019-05-20T00:00:00-04:00","relpermalink":"/publication/wu2019identifying/","section":"publication","summary":"","tags":[],"title":"Identifying Functional Brain Connectivity Patterns for EEG-Based Emotion Recognition","type":"publication"},{"authors":["**Wei-Long Zheng**","Kunpeng Gao","Gang Li","Wei Liu","Chao Liu","Jing-Quan Liu","Guoxing Wang","Bao-Liang Lu"],"categories":null,"content":"","date":1548046800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1548046800,"objectID":"250b1948baf63320168d918e8550e331","permalink":"https://weilongzheng.github.io/publication/zheng2019vigilance/","publishdate":"2019-01-21T00:00:00-05:00","relpermalink":"/publication/zheng2019vigilance/","section":"publication","summary":"Vigilance decrement in driving tasks has been reported to be a major factor in fatal accidents and could severely endanger public transportation safety. However, efficient approaches for estimating vigilance in real driving environment are still lacking. In this paper, we propose a novel approach for implementing continuous vigilance estimation using forehead electrooculograms (EOGs) acquired by wearable dry electrodes in both simulated and real driving environments. To improve the feasibility of this approach for real-world applications, a forehead EOG-based electrode placement with only four electrodes is designed. Flexible dry electrodes and an acquisition board are integrated as a wearable device for recording EOGs. Twenty and ten subjects participated in the simulated and real-world driving environment experiments, respectively. Accurate eye movement parameters from eye-tracking glasses are extracted to calculate the PERCLOS index for vigilance annotation. This is because the vigilance state is a temporally dynamic process, and a continuous conditional random field and a continuous conditional neural field are introduced to construct more accurate vigilance estimation models. To evaluate the efficiency of our system, systematic experiments are performed in real scenarios under various illumination and weather conditions following laboratory simulations as preliminary studies. The experimental results demonstrate that the wearable dry electrode prototype, which has a relatively comfortable forehead setup, can efficiently capture vigilance dynamics. The best mean correlation coefficients achieved by our proposed approach are 71.18% and 66.20% in laboratory simulations and real-world driving environments, respectively. The cross-environment experiments are performed to evaluate the simulated-to-real generalization and a best mean correlation coefficient of 53.96% is achieved.","tags":[],"title":"Vigilance Estimation Using a Wearable EOG Device in Real Driving Environment","type":"publication"},{"authors":["Wei Wu","Q. M. Jonathan Wu","Wei Sun","Yimin Yang","Xiaofang Yuan","**Wei-Long Zheng**","Bao-Liang Lu"],"categories":null,"content":"","date":1545368400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1545368400,"objectID":"0380d1445d909dc0f0e2a02bab0fff60","permalink":"https://weilongzheng.github.io/publication/wu2018regression/","publishdate":"2018-12-21T00:00:00-05:00","relpermalink":"/publication/wu2018regression/","section":"publication","summary":"","tags":[],"title":"A regression method with subnetwork neurons for vigilance estimation using EOG and EEG","type":"publication"},{"authors":["Li-Ming Zhao","Xin-Wei Li","**Wei-Long Zheng**","Bao-Liang Lu"],"categories":null,"content":"","date":1542430800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1542430800,"objectID":"4a049642ac4e258b34d0c816a64c42cd","permalink":"https://weilongzheng.github.io/publication/zhao2018active/","publishdate":"2018-11-17T00:00:00-05:00","relpermalink":"/publication/zhao2018active/","section":"publication","summary":"","tags":[],"title":"Active Feedback Framework with Scan-Path Clustering for Deep Affective Models","type":"publication"},{"authors":["He Li","Yi-Ming Jin","**Wei-Long Zheng**","Bao-Liang Lu"],"categories":null,"content":"","date":1542430800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1542430800,"objectID":"c11fcf8651629438c7835600f298c644","permalink":"https://weilongzheng.github.io/publication/li2018cross/","publishdate":"2018-11-17T00:00:00-05:00","relpermalink":"/publication/li2018cross/","section":"publication","summary":"","tags":[],"title":"Cross-Subject Emotion Recognition Using Deep Adaptation Networks","type":"publication"},{"authors":["Yun Luo","Si-Yang Zhang","**Wei-Long Zheng**","Bao-Liang Lu"],"categories":null,"content":"","date":1542430800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1542430800,"objectID":"22e15b9d19e368a93d17e03273b63a26","permalink":"https://weilongzheng.github.io/publication/luo2018wgan/","publishdate":"2018-11-17T00:00:00-05:00","relpermalink":"/publication/luo2018wgan/","section":"publication","summary":"","tags":[],"title":"WGAN Domain Adaptation for EEG-Based Emotion Recognition","type":"publication"},{"authors":null,"categories":null,"content":"","date":1540612800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1540612800,"objectID":"591df82f86ed495bafe07ffeaee72ed9","permalink":"https://weilongzheng.github.io/project/icu/","publishdate":"2018-10-27T00:00:00-04:00","relpermalink":"/project/icu/","section":"project","summary":"Time series signal analysis and machine learning to improve clinical healthcare.","tags":[],"title":"Clinical Healthcare","type":"project"},{"authors":null,"categories":null,"content":"","date":1540612800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1540612800,"objectID":"f3666a831e5f343d86b70ffd571d7209","permalink":"https://weilongzheng.github.io/project/coma/","publishdate":"2018-10-27T00:00:00-04:00","relpermalink":"/project/coma/","section":"project","summary":"Investigate the relationship between various EEG patterns and coma outcomes for patients after cardiac arrest.","tags":[],"title":"Coma Prognostication","type":"project"},{"authors":["Changde Du","Changying Du","Hao Wang","Jinpeng Li","**Wei-Long Zheng**","Bao-Liang Lu","Huiguang He"],"categories":null,"content":"","date":1540180800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1540180800,"objectID":"dcd00041ab97443227c8c494b7648063","permalink":"https://weilongzheng.github.io/publication/du2018semi/","publishdate":"2018-10-22T00:00:00-04:00","relpermalink":"/publication/du2018semi/","section":"publication","summary":"","tags":[],"title":"Semi-supervised Deep Generative Modelling of Incomplete Multi-Modality Emotional Data","type":"publication"},{"authors":["He Li","**Wei-Long Zheng**","Bao-Liang Lu"],"categories":null,"content":"","date":1539576000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1539576000,"objectID":"443aaec08087a843999549997085191a","permalink":"https://weilongzheng.github.io/publication/li2018multimodal/","publishdate":"2018-10-15T00:00:00-04:00","relpermalink":"/publication/li2018multimodal/","section":"publication","summary":"","tags":[],"title":"Multimodal Vigilance Estimation with Adversarial Domain Adaptation Networks","type":"publication"},{"authors":["Jia-Jun Tong","Yun Luo","Bo-Qun Ma","**Wei-Long Zheng**","Bao-Liang Lu","Xiao-Qi Song","Shi-Wei Ma"],"categories":null,"content":"","date":1539576000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1539576000,"objectID":"5faa0772b9d939f816ae4323f4bc04c6","permalink":"https://weilongzheng.github.io/publication/tong2018sleep/","publishdate":"2018-10-15T00:00:00-04:00","relpermalink":"/publication/tong2018sleep/","section":"publication","summary":"","tags":[],"title":"Sleep Quality Estimation with Adversarial Domain Adaptation: From Laboratory to Real Scenario","type":"publication"},{"authors":["**Wei-Long Zheng**"],"categories":null,"content":"","date":1529899200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1529899200,"objectID":"20169f5cc4a3d65d11f36288ff375063","permalink":"https://weilongzheng.github.io/publication/zheng2018thesis/","publishdate":"2018-06-25T00:00:00-04:00","relpermalink":"/publication/zheng2018thesis/","section":"publication","summary":"","tags":[],"title":"Affective Brain-Computer Interactions","type":"publication"},{"authors":null,"categories":null,"content":"","date":1524801600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1524801600,"objectID":"3b3a53ae7d1c7e3081be98a3d7ee332d","permalink":"https://weilongzheng.github.io/project/emotion/","publishdate":"2018-04-27T00:00:00-04:00","relpermalink":"/project/emotion/","section":"project","summary":"Multimodal emotion recognition using EEG and eye movements.","tags":[],"title":"Affective Brain-Comouter Interactions","type":"project"},{"authors":null,"categories":null,"content":"","date":1524801600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1524801600,"objectID":"dd6c15798e78e0ebec8824c52ba3c9aa","permalink":"https://weilongzheng.github.io/datasets/seed-iv/","publishdate":"2018-04-27T00:00:00-04:00","relpermalink":"/datasets/seed-iv/","section":"datasets","summary":"SJTU Emotion EEG Dataset (SEED-IV) of four emotions: happy, sad, fear, and neutral.","tags":[],"title":"SEED-IV","type":"datasets"},{"authors":["**Wei-Long Zheng**","Wei Liu","Yifei Lu","Bao-Liang Lu","Andrzej Cichocki"],"categories":null,"content":"","date":1518066000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1518066000,"objectID":"d23329cafc6af38e7e8a4cbb99958484","permalink":"https://weilongzheng.github.io/publication/zheng2018emotionmeter/","publishdate":"2018-02-08T00:00:00-05:00","relpermalink":"/publication/zheng2018emotionmeter/","section":"publication","summary":"In this paper, we present a multimodal emotion recognition framework called EmotionMeter that combines brain waves and eye movements. To increase the feasibility and wearability of EmotionMeter in real-world applications, we design a six-electrode placement above the ears to collect electroencephalography (EEG) signals. We combine EEG and eye movements for integrating the internal cognitive states and external subconscious behaviors of users to improve the recognition accuracy of EmotionMeter . The experimental results demonstrate that modality fusion with multimodal deep neural networks can significantly enhance the performance compared with a single modality, and the best mean accuracy of 85.11% is achieved for four emotions (happy, sad, fear, and neutral). We explore the complementary characteristics of EEG and eye movements for their representational capacities and identify that EEG has the advantage of classifying happy emotion, whereas eye movements outperform EEG in recognizing fear emotion. To investigate the stability of EmotionMeter over time, each subject performs the experiments three times on different days. EmotionMeter obtains a mean recognition accuracy of 72.39% across sessions with the six-electrode EEG and eye movement features. These experimental results demonstrate the effectiveness of EmotionMeter within and between sessions.","tags":[],"title":"Emotionmeter: A multimodal framework for recognizing human emotions","type":"publication"},{"authors":["Yi-Ming Jin","Yu-Dong Luo","**Wei-Long Zheng**","Bao-Liang Lu"],"categories":null,"content":"","date":1512709200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1512709200,"objectID":"7af7337bc4b9f7d3e59d80c4a46d6cc1","permalink":"https://weilongzheng.github.io/publication/jin2017eeg/","publishdate":"2017-12-08T00:00:00-05:00","relpermalink":"/publication/jin2017eeg/","section":"publication","summary":"","tags":[],"title":"EEG-based emotion recognition using domain adaptation network","type":"publication"},{"authors":["Xing-Zan Zhang","**Wei-Long Zheng**","Bao-Liang Lu"],"categories":null,"content":"","date":1508817600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1508817600,"objectID":"f6525c85c184007890a41a554ee0dc05","permalink":"https://weilongzheng.github.io/publication/zhang2017eeg/","publishdate":"2017-10-24T00:00:00-04:00","relpermalink":"/publication/zhang2017eeg/","section":"publication","summary":"","tags":[],"title":"EEG-based sleep quality evaluation with deep transfer learning","type":"publication"},{"authors":["Wei-Ye Zhao","Sheng Fang","Ting Ji","Qian Ji","**Wei-Long Zheng**","Bao-Liang Lu"],"categories":null,"content":"","date":1508817600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1508817600,"objectID":"6b1b143a9a9c630bdf7d6005f14dceda","permalink":"https://weilongzheng.github.io/publication/zhao2017emotion/","publishdate":"2017-10-24T00:00:00-04:00","relpermalink":"/publication/zhao2017emotion/","section":"publication","summary":"","tags":[],"title":"Emotion Annotation Using Hierarchical Aligned Cluster Analysis","type":"publication"},{"authors":["Xue Yan","**Wei-Long Zheng**","Wei Liu","Bao-Liang Lu"],"categories":null,"content":"","date":1508817600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1508817600,"objectID":"3b47b6e3f2d746dcd32c9789eccb4e7c","permalink":"https://weilongzheng.github.io/publication/yan2017identifying/","publishdate":"2017-10-24T00:00:00-04:00","relpermalink":"/publication/yan2017identifying/","section":"publication","summary":"","tags":[],"title":"Identifying Gender Differences in Multimodal Emotion Recognition Using Bimodal Deep AutoEncoder","type":"publication"},{"authors":["Xue Yan","**Wei-Long Zheng**","Wei Liu","Bao-Liang Lu"],"categories":null,"content":"","date":1508817600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1508817600,"objectID":"2b8cdf6a7153eaca91e919807b9c0547","permalink":"https://weilongzheng.github.io/publication/yan2017investigating/","publishdate":"2017-10-24T00:00:00-04:00","relpermalink":"/publication/yan2017investigating/","section":"publication","summary":"","tags":[],"title":"Investigating gender differences of brain areas in emotion recognition using LSTM neural network","type":"publication"},{"authors":["Hao Tang","Wei Liu","**Wei-Long Zheng**","Bao-Liang Lu"],"categories":null,"content":"","date":1508817600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1508817600,"objectID":"d1f9cd84bdd087766ad867a161171041","permalink":"https://weilongzheng.github.io/publication/tang2017multimodal/","publishdate":"2017-10-24T00:00:00-04:00","relpermalink":"/publication/tang2017multimodal/","section":"publication","summary":"","tags":[],"title":"Multimodal emotion recognition using deep neural networks","type":"publication"},{"authors":["Zhen-Feng Shi","Chang Zhou","**Wei-Long Zheng**","Bao-Liang Lu"],"categories":null,"content":"","date":1502769600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1502769600,"objectID":"6c07d46e48918f45df383c2bc7bf0b7f","permalink":"https://weilongzheng.github.io/publication/shi2017attention/","publishdate":"2017-08-15T00:00:00-04:00","relpermalink":"/publication/shi2017attention/","section":"publication","summary":"","tags":[],"title":"Attention evaluation with eye tracking glasses for EEG-based emotion recognition","type":"publication"},{"authors":["Li-Huan Du","Wei Liu","**Wei-Long Zheng**","Bao-Liang Lu"],"categories":null,"content":"","date":1502769600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1502769600,"objectID":"b5bc1eb13a0d84240490f06d4d37b0b9","permalink":"https://weilongzheng.github.io/publication/du2017detecting/","publishdate":"2017-08-15T00:00:00-04:00","relpermalink":"/publication/du2017detecting/","section":"publication","summary":"","tags":[],"title":"Detecting driving fatigue with multimodal deep learning","type":"publication"},{"authors":["Si-Yuan Wu","Moritz Schaefer","**Wei-Long Zheng**","Bao-Liang Lu","Hiroshi Yokoi"],"categories":null,"content":"","date":1502769600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1502769600,"objectID":"cf2008747fcc2591d36401f636ad3123","permalink":"https://weilongzheng.github.io/publication/wu2017neural/","publishdate":"2017-08-15T00:00:00-04:00","relpermalink":"/publication/wu2017neural/","section":"publication","summary":"","tags":[],"title":"Neural patterns between Chinese and Germans for EEG-based emotion recognition","type":"publication"},{"authors":["**Wei-Long Zheng**","Jia-Yi Zhu","Bao-Liang Lu"],"categories":null,"content":"","date":1496635200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1496635200,"objectID":"71d71fdce9b0183960e5f7421be07afa","permalink":"https://weilongzheng.github.io/publication/zheng2017identifying/","publishdate":"2017-06-05T00:00:00-04:00","relpermalink":"/publication/zheng2017identifying/","section":"publication","summary":"In this paper, we investigate stable patterns of electroencephalogram (EEG) over time for emotion recognition using a machine learning approach. Up to now, various findings of activated patterns associated with different emotions have been reported. However, their stability over time has not been fully investigated yet. In this paper, we focus on identifying EEG stability in emotion recognition. We systematically evaluate the performance of various popular feature extraction, feature selection, feature smoothing and pattern classification methods with the DEAP dataset and a newly developed dataset called SEED for this study. Discriminative Graph regularized Extreme Learning Machine with differential entropy features achieves the best average accuracies of 69.67% and 91.07% on the DEAP and SEED datasets, respectively. The experimental results indicate that stable patterns exhibit consistency across sessions; the lateral temporal areas activate more for positive emotions than negative emotions in beta and gamma bands; the neural patterns of neutral emotions have higher alpha responses at parietal and occipital sites; and for negative emotions, the neural patterns have significant higher delta responses at parietal and occipital sites and higher gamma responses at prefrontal sites. The performance of our emotion recognition models shows that the neural patterns are relatively stable within and between sessions.","tags":[],"title":"Identifying stable patterns over time for emotion recognition from EEG","type":"publication"},{"authors":null,"categories":null,"content":"","date":1493265600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1493265600,"objectID":"51ffca6fccc96e29e36d3d04c922b7d9","permalink":"https://weilongzheng.github.io/datasets/seed-vig/","publishdate":"2017-04-27T00:00:00-04:00","relpermalink":"/datasets/seed-vig/","section":"datasets","summary":"A Multimodal Dataset with EEG and Forehead EOG for Vigilance Estimation (SEED-VIG).","tags":[],"title":"SEED-VIG","type":"datasets"},{"authors":null,"categories":null,"content":"","date":1493265600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1493265600,"objectID":"c995a9e5e77971e4dba2bb0ea51e1730","permalink":"https://weilongzheng.github.io/project/vigilance/","publishdate":"2017-04-27T00:00:00-04:00","relpermalink":"/project/vigilance/","section":"project","summary":"Multimodal Vigilance Estimation using EEG and EOG: From Simulated To Real Environments.","tags":[],"title":"Vigilance Estimation","type":"project"},{"authors":["Changde Du","Changying Du","Jinpeng Li","**Wei-long Zheng**","Bao-liang Lu","Huiguang He"],"categories":null,"content":"","date":1493092800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1493092800,"objectID":"1550711a7f06977640c9ef818b106263","permalink":"https://weilongzheng.github.io/publication/du2017semi/","publishdate":"2017-04-25T00:00:00-04:00","relpermalink":"/publication/du2017semi/","section":"publication","summary":"","tags":[],"title":"Semi-supervised Bayesian Deep Multi-modal Emotion Recognition","type":"publication"},{"authors":["Yimin Yang","Q. M. Jonathan Wu","**Wei-Long Zheng**","Bao-Liang Lu"],"categories":null,"content":"","date":1490068800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1490068800,"objectID":"d3083ec148404c7a2d0e4d5578328cc6","permalink":"https://weilongzheng.github.io/publication/yang2018eeg/","publishdate":"2017-03-21T00:00:00-04:00","relpermalink":"/publication/yang2018eeg/","section":"publication","summary":"","tags":[],"title":"EEG-based emotion recognition using hierarchical network with subnetwork nodes","type":"publication"},{"authors":["**Wei-Long Zheng**","Bao-Liang Lu"],"categories":null,"content":"","date":1487739600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1487739600,"objectID":"f453b5326518ac5812d2c2565488c100","permalink":"https://weilongzheng.github.io/publication/zheng2017multimodal/","publishdate":"2017-02-22T00:00:00-05:00","relpermalink":"/publication/zheng2017multimodal/","section":"publication","summary":"Objective. Covert aspects of ongoing user mental states provide key context information for user-aware human computer interactions. In this paper, we focus on the problem of estimating the vigilance of users using EEG and EOG signals. Approach. The PERCLOS index as vigilance annotation is obtained from eye tracking glasses. To improve the feasibility and wearability of vigilance estimation devices for real-world applications, we adopt a novel electrode placement for forehead EOG and extract various eye movement features, which contain the principal information of traditional EOG. We explore the effects of EEG from different brain areas and combine EEG and forehead EOG to leverage their complementary characteristics for vigilance estimation. Considering that the vigilance of users is a dynamic changing process because the intrinsic mental states of users involve temporal evolution, we introduce continuous conditional neural field and continuous conditional random field models to capture dynamic temporal dependency. Main results. We propose a multimodal approach to estimating vigilance by combining EEG and forehead EOG and incorporating the temporal dependency of vigilance into model training. The experimental results demonstrate that modality fusion can improve the performance compared with a single modality, EOG and EEG contain complementary information for vigilance estimation, and the temporal dependency-based models can enhance the performance of vigilance estimation. From the experimental results, we observe that theta and alpha frequency activities are increased, while gamma frequency activities are decreased in drowsy states in contrast to awake states. Significance. The forehead setup allows for the simultaneous collection of EEG and EOG and achieves comparative ","tags":[],"title":"A multimodal approach to estimating vigilance using EEG and forehead EOG","type":"publication"},{"authors":["Xue-Qin Huo","**Wei-Long Zheng**","Bao-Liang Lu"],"categories":null,"content":"","date":1478145600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1478145600,"objectID":"918c552cb26866172f706b8fcea18255","permalink":"https://weilongzheng.github.io/publication/huo2016driving/","publishdate":"2016-11-03T00:00:00-04:00","relpermalink":"/publication/huo2016driving/","section":"publication","summary":"","tags":[],"title":"Driving fatigue detection with fusion of EEG and forehead EOG","type":"publication"},{"authors":["Li-Li Wang","**Wei-Long Zheng**","Hai-Wei Ma","Bao-Liang Lu"],"categories":null,"content":"","date":1478145600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1478145600,"objectID":"4adcb4a652c37a6c01009760f49bfa91","permalink":"https://weilongzheng.github.io/publication/wang2016measuring/","publishdate":"2016-11-03T00:00:00-04:00","relpermalink":"/publication/wang2016measuring/","section":"publication","summary":"","tags":[],"title":"Measuring sleep quality from EEG with machine learning approaches","type":"publication"},{"authors":["Nan Zhang","**Wei-Long Zheng**","Wei Liu","Bao-Liang Lu"],"categories":null,"content":"","date":1475208000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1475208000,"objectID":"235f75c9b48652f48068e70dda9108bc","permalink":"https://weilongzheng.github.io/publication/zhang2016continuous/","publishdate":"2016-09-30T00:00:00-04:00","relpermalink":"/publication/zhang2016continuous/","section":"publication","summary":"","tags":[],"title":"Continuous vigilance estimation using LSTM neural networks","type":"publication"},{"authors":["Wei Liu","**Wei-Long Zheng**","Bao-Liang Lu"],"categories":null,"content":"","date":1475208000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1475208000,"objectID":"25e22759e400adbb6685c7a20167d7fb","permalink":"https://weilongzheng.github.io/publication/liu2016emotion/","publishdate":"2016-09-30T00:00:00-04:00","relpermalink":"/publication/liu2016emotion/","section":"publication","summary":"","tags":[],"title":"Emotion recognition using multimodal deep learning","type":"publication"},{"authors":["**Wei-Long Zheng**","Bao-Liang Lu"],"categories":null,"content":"","date":1468036800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1468036800,"objectID":"99fc2761ca6994eae6ae92a0b4b3602b","permalink":"https://weilongzheng.github.io/publication/zheng2016personalizing/","publishdate":"2016-07-09T00:00:00-04:00","relpermalink":"/publication/zheng2016personalizing/","section":"publication","summary":"Individual differences across subjects and nonstationary characteristic of electroencephalography (EEG) limit the generalization of affective brain-computer interfaces in real-world applications. On the other hand, it is very time consuming and expensive to acquire a large number of subject-specific labeled data for learning subject-specific models. In this paper, we propose to build personalized EEG-based affective models without labeled target data using transfer learning techniques. We mainly explore two types of subject-to-subject transfer approaches. One is to exploit shared structure underlying source domain (source subject) and target domain (target subject). The other is to train multiple individual classifiers on source subjects and transfer knowledge about classifier parameters to target subjects, and its aim is to learn a regression function that maps the relationship between feature distribution and classifier parameters. We compare the performance of five different approaches on an EEG dataset for constructing an affective model with three affective states: positive, neutral, and negative. The experimental results demonstrate that our proposed subject transfer framework achieves the mean accuracy of 76.31% in comparison with a conventional generic classifier with 56.73% in average.","tags":[],"title":"Personalizing EEG-based affective models with transfer learning","type":"publication"},{"authors":null,"categories":null,"content":"","date":1461729600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461729600,"objectID":"6109bfd76c04dbc76005e7316a4dc31e","permalink":"https://weilongzheng.github.io/project/transfer/","publishdate":"2016-04-27T00:00:00-04:00","relpermalink":"/project/transfer/","section":"project","summary":"Transfer learning algorithms are used to tackle individual differences across subjects and sessions and non-stationary characteristics of EEG.","tags":[],"title":"Transfer Learning","type":"project"},{"authors":["Wei Liu","**Wei-Long Zheng**","Bao-Liang Lu"],"categories":null,"content":"","date":1456462800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1456462800,"objectID":"b222b7f62703a4eb51d60a27233a31d7","permalink":"https://weilongzheng.github.io/publication/liu2016multimodal/","publishdate":"2016-02-26T00:00:00-05:00","relpermalink":"/publication/liu2016multimodal/","section":"publication","summary":"","tags":[],"title":"Multimodal emotion recognition using multimodal deep learning","type":"publication"},{"authors":["**Wei-Long Zheng**","Shan-Chun Shen","Bao-Liang Lu"],"categories":null,"content":"","date":1455858000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1455858000,"objectID":"ca0ce6c6587dd1936684ca4087674c4c","permalink":"https://weilongzheng.github.io/publication/zheng2017online/","publishdate":"2016-02-19T00:00:00-05:00","relpermalink":"/publication/zheng2017online/","section":"publication","summary":"","tags":[],"title":"Online depth image-based object tracking with sparse representation and object detection","type":"publication"},{"authors":["Yong Peng","**Wei-Long Zheng**","Bao-Liang Lu"],"categories":null,"content":"","date":1453438800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1453438800,"objectID":"c28ca841cceda1538ea4b296695ffcdf","permalink":"https://weilongzheng.github.io/publication/peng2016unsupervised/","publishdate":"2016-01-22T00:00:00-05:00","relpermalink":"/publication/peng2016unsupervised/","section":"publication","summary":"","tags":[],"title":"An unsupervised discriminative extreme learning machine and its applications to data clustering","type":"publication"},{"authors":["Yong-Qi Zhang","**Wei-Long Zheng**","Bao-Liang Lu"],"categories":null,"content":"","date":1447822800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1447822800,"objectID":"23dff1784fcf9344d52b1ee60927dad0","permalink":"https://weilongzheng.github.io/publication/zhang2015transfer/","publishdate":"2015-11-18T00:00:00-05:00","relpermalink":"/publication/zhang2015transfer/","section":"publication","summary":"","tags":[],"title":"Transfer components between subjects for EEG-based driving fatigue detection","type":"publication"},{"authors":["**Wei-Long Zheng**","Yong-Qi Zhang","Jia-Yi Zhu","Bao-Liang Lu"],"categories":null,"content":"","date":1442808000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1442808000,"objectID":"27413c56ada88828b5d4dc3fb7f6aa78","permalink":"https://weilongzheng.github.io/publication/zheng2015transfer/","publishdate":"2015-09-21T00:00:00-04:00","relpermalink":"/publication/zheng2015transfer/","section":"publication","summary":"","tags":[],"title":"Transfer components between subjects for EEG-based emotion recognition","type":"publication"},{"authors":["Yu-Fei Zhang","Xiang-Yu Gao","Jia-Yi Zhu","**Wei-Long Zheng**","Bao-Liang Lu"],"categories":null,"content":"","date":1435809600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1435809600,"objectID":"95193da73add2c552f8a606e2445db18","permalink":"https://weilongzheng.github.io/publication/zhang2015novel/","publishdate":"2015-07-02T00:00:00-04:00","relpermalink":"/publication/zhang2015novel/","section":"publication","summary":"","tags":[],"title":"A novel approach to driving fatigue detection using forehead EOG","type":"publication"},{"authors":["Xiang-Yu Gao","Yu-Fei Zhang","**Wei-Long Zheng**","Bao-Liang Lu"],"categories":null,"content":"","date":1435809600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1435809600,"objectID":"dde58e7a3b261f7df50aedbebfff7353","permalink":"https://weilongzheng.github.io/publication/gao2015evaluating/","publishdate":"2015-07-02T00:00:00-04:00","relpermalink":"/publication/gao2015evaluating/","section":"publication","summary":"","tags":[],"title":"Evaluating driving fatigue detection algorithms using eye tracking glasses","type":"publication"},{"authors":["**Wei-Long Zheng**","Hao-Tian Guo","Bao-Liang Lu"],"categories":null,"content":"","date":1435809600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1435809600,"objectID":"ec87daa93f3ce61d412afef32e91ea8e","permalink":"https://weilongzheng.github.io/publication/zheng2015revealing/","publishdate":"2015-07-02T00:00:00-04:00","relpermalink":"/publication/zheng2015revealing/","section":"publication","summary":"","tags":[],"title":"Revealing critical channels and frequency bands for emotion recognition from EEG with deep belief network","type":"publication"},{"authors":["Yifei Lu*","**Wei-Long Zheng***","Binbin Li","Bao-Liang Lu"],"categories":null,"content":"","date":1435032000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1435032000,"objectID":"25e48ce6f342e6e73b71877eacef54a1","permalink":"https://weilongzheng.github.io/publication/lu2015combining/","publishdate":"2015-06-23T00:00:00-04:00","relpermalink":"/publication/lu2015combining/","section":"publication","summary":"In this paper, we adopt a multimodal emotion recognition framework by combining eye movements and electroencephalography (EEG) to enhance emotion recognition. The main contributions of this paper are twofold. a) We investigate sixteen eye movements related to emotions and identify the intrinsic patterns of these eye movements for three emotional states: positive, neutral and negative. b) We examine various modality fusion strategies for integrating users external subconscious behaviors and internal cognitive states and reveal that the characteristics of eye movements and EEG are complementary to emotion recognition. Experiment results demonstrate that modality fusion could significantly improve emotion recognition accuracy in comparison with single modality. The best accuracy achieved by fuzzy integral fusion strategy is 87.59%, whereas the accuracies of solely using eye movements and EEG data are 77.80% and 78.51%, respectively.","tags":[],"title":"Combining eye movements and EEG to enhance emotion recognition","type":"publication"},{"authors":["**Wei-Long Zheng**","Roberto Santana","Bao-Liang Lu"],"categories":null,"content":"","date":1433649600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1433649600,"objectID":"02d88cb8c75601601ec038c4887aa191","permalink":"https://weilongzheng.github.io/publication/zheng2015comparison/","publishdate":"2015-06-07T00:00:00-04:00","relpermalink":"/publication/zheng2015comparison/","section":"publication","summary":"","tags":[],"title":"Comparison of classification methods for EEG-based emotion recognition","type":"publication"},{"authors":["Jia-Yi Zhu","**Wei-Long Zheng**","Bao-Liang Lu"],"categories":null,"content":"","date":1433649600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1433649600,"objectID":"785d5b2596ae538a34b5cf9088e9696e","permalink":"https://weilongzheng.github.io/publication/zhu2015cross/","publishdate":"2015-06-07T00:00:00-04:00","relpermalink":"/publication/zhu2015cross/","section":"publication","summary":"","tags":[],"title":"Cross-subject and cross-gender emotion classification from EEG","type":"publication"},{"authors":["**Wei-Long Zheng**","Bao-Liang Lu"],"categories":null,"content":"","date":1431057600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1431057600,"objectID":"a1d7c08597266fa724529bfbbb1b00e9","permalink":"https://weilongzheng.github.io/publication/zheng2015investigating/","publishdate":"2015-05-08T00:00:00-04:00","relpermalink":"/publication/zheng2015investigating/","section":"publication","summary":"To investigate critical frequency bands and channels, this paper introduces deep belief networks (DBNs) to constructing EEG-based emotion recognition models for three emotions: positive, neutral and negative. We develop an EEG dataset acquired from 15 subjects. Each subject performs the experiments twice at the interval of a few days. DBNs are trained with differential entropy features extracted from multichannel EEG data. We examine the weights of the trained DBNs and investigate the critical frequency bands and channels. Four different profiles of 4, 6, 9, and 12 channels are selected. The recognition accuracies of these four profiles are relatively stable with the best accuracy of 86.65%, which is even better than that of the original 62 channels. The critical frequency bands and channels determined by using the weights of trained DBNs are consistent with the existing observations. In addition, our experiment results show that neural signatures associated with different emotions do exist and they share commonality across sessions and individuals. We compare the performance of deep models with shallow models. The average accuracies of DBN, SVM, LR, and KNN are 86.08%, 83.99%, 82.70%, and 72.60%, respectively.","tags":[],"title":"Investigating critical frequency bands and channels for EEG-based emotion recognition with deep neural networks","type":"publication"},{"authors":null,"categories":null,"content":"","date":1430107200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1430107200,"objectID":"37df4810ed8142b64c74cf78f524a3c1","permalink":"https://weilongzheng.github.io/datasets/seed/","publishdate":"2015-04-27T00:00:00-04:00","relpermalink":"/datasets/seed/","section":"datasets","summary":"SJTU Emotion EEG Dataset (SEED) of three emotions: positive, neutral, and negative.","tags":[],"title":"SEED","type":"datasets"},{"authors":["Yong Peng","Jia-Yi Zhu","**Wei-Long Zheng**","Bao-Liang Lu"],"categories":null,"content":"","date":1415250000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1415250000,"objectID":"ecd31cac8f82b13d9ef0861032e1649c","permalink":"https://weilongzheng.github.io/publication/peng2014eeg/","publishdate":"2014-11-06T00:00:00-05:00","relpermalink":"/publication/peng2014eeg/","section":"publication","summary":"","tags":[],"title":"EEG-based emotion recognition with manifold regularized extreme learning machine","type":"publication"},{"authors":["**Wei-Long Zheng**","Bo-Nan Dong","Bao-Liang Lu"],"categories":null,"content":"","date":1415250000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1415250000,"objectID":"da7a32e53f966f422ab1e3aabbb680ba","permalink":"https://weilongzheng.github.io/publication/zheng2014multimodal/","publishdate":"2014-11-06T00:00:00-05:00","relpermalink":"/publication/zheng2014multimodal/","section":"publication","summary":"","tags":[],"title":"Multimodal emotion recognition using EEG and eye tracking data","type":"publication"},{"authors":["**Wei-Long Zheng**","Jia-Yi Zhu","Bao-Liang Lu"],"categories":null,"content":"","date":1415250000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1415250000,"objectID":"f151517e84f8e480a531850b972da6a6","permalink":"https://weilongzheng.github.io/publication/zheng2014multimodel2/","publishdate":"2014-11-06T00:00:00-05:00","relpermalink":"/publication/zheng2014multimodel2/","section":"publication","summary":"","tags":[],"title":"Multimodel emotion analysis in response to multimedia","type":"publication"},{"authors":["Shan-Chun Shen","**Wei-Long Zheng**","Bao-Liang Lu"],"categories":null,"content":"","date":1414990800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1414990800,"objectID":"ee34a639c311ddf551ee27fc529dfd20","permalink":"https://weilongzheng.github.io/publication/shen2014online/","publishdate":"2014-11-03T00:00:00-05:00","relpermalink":"/publication/shen2014online/","section":"publication","summary":"","tags":[],"title":"Online object tracking based on depth image with sparse coding","type":"publication"},{"authors":["**Wei-Long Zheng**","Jia-Yi Zhu","Yong Peng","Bao-Liang Lu"],"categories":null,"content":"","date":1410148800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1410148800,"objectID":"1d591023d16ddaa4366a64d8fb1e8bb5","permalink":"https://weilongzheng.github.io/publication/zheng2014eeg/","publishdate":"2014-09-08T00:00:00-04:00","relpermalink":"/publication/zheng2014eeg/","section":"publication","summary":"In recent years, there are many great successes in using deep architectures for unsupervised feature learning from data, especially for images and speech. In this paper, we introduce recent advanced deep learning models to classify two emotional categories (positive and negative) from EEG data. We train a deep belief network (DBN) with differential entropy features extracted from multichannel EEG as input. A hidden markov model (HMM) is integrated to accurately capture a more reliable emotional stage switching. We also compare the performance of the deep models to KNN, SVM and Graph regularized Extreme Learning Machine (GELM). The average accuracies of DBN-HMM, DBN, GELM, SVM, and KNN in our experiments are 87.62%, 86.91%, 85.67%, 84.08%, and 69.66%, respectively. Our experimental results show that the DBN and DBN-HMM models improve the accuracy of EEG-based emotion classification in comparison with the state-of-the-art methods.","tags":[],"title":"EEG-based emotion classification using deep belief networks","type":"publication"},{"authors":["Jia-Yi Zhu","**Wei-Long Zheng**","Ruo-Nan Duan","Yong Peng","Bao-Liang Lu"],"categories":null,"content":"","date":1409803200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1409803200,"objectID":"c65f9432a5228a4ef4c0bbf1286a1046","permalink":"https://weilongzheng.github.io/publication/zhu2014eeg/","publishdate":"2014-09-04T00:00:00-04:00","relpermalink":"/publication/zhu2014eeg/","section":"publication","summary":"","tags":[],"title":"EEG-based emotion recognition using discriminative graph regularized extreme learning machine","type":"publication"},{"authors":["Xuemin Zhu","**Wei-Long Zheng**","Bao-Liang Lu","Xiaoping Chen","Shanguang Chen","Chunhui Wang"],"categories":null,"content":"","date":1409803200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1409803200,"objectID":"fb22348673ae65c0a84a2128523dd7f3","permalink":"https://weilongzheng.github.io/publication/zhu2014eog/","publishdate":"2014-09-04T00:00:00-04:00","relpermalink":"/publication/zhu2014eog/","section":"publication","summary":"","tags":[],"title":"EOG-based drowsiness detection using convolutional neural networks","type":"publication"},{"authors":["Simin Zhao","Xiangming Xu","**Wei-Long Zheng**","Jianwen Ling"],"categories":null,"content":"","date":1338782400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1338782400,"objectID":"d7dc5f2b38bd1fd1b08bfb2ef1795aad","permalink":"https://weilongzheng.github.io/publication/zhao2012registration/","publishdate":"2012-06-04T00:00:00-04:00","relpermalink":"/publication/zhao2012registration/","section":"publication","summary":"","tags":[],"title":"Registration of depth image and color image based on Harris-SIFT","type":"publication"}]