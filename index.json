[{"authors":null,"categories":null,"content":"Always looking for highly-motivated students and postdocs to join our team to work on understanding how the brain works! Feel free to email me if you are interested!\nHi, I am currently a Tenured-Track Associate Professor in Department of Computer Science and Engineering, Shanghai Jiao Tong University. My lab is Center for Brain-like Computing and Machine Intelligence (BCMI). My research interests cover the broad areas of affective brain-computer interfaces, computational neuroscience, machine learning, AI, clinical healthcare, and biomedical engineering.\nPrior to SJTU, I was a Postdoc Associate in Department of Brain and Cognitive Science at Massachusetts Institute of Technology (MIT). I worked with Michael Halassa and Robert Yang on developing computational models for thalamocortical interactions in cognition. I was also a research fellow in Department of Neurology, Massachusetts General Hospital, Harvard Medical School, working with M Brandon Westover, MD, PhD. I obtained my PhD degree in the Center for Brain-Like Computing and Machine Intelligence, Department of Computer Science, Shanghai Jiao Tong University, China, supervised by Bao-Liang Lu.I obtained my Bachelor degree from Talented Student Program in Department of Electronic and Information Engineering, South China University of Technology, China. I was a visiting researcher in The Cichocki Laboratory for Advanced Brain Signal Processing, Brain Science Institute, RIKEN, Japan, and in Intelligent Systems Group, Department of Computer Science and Artificial Intelligence, University of the Basque Country, Spain.\n","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":-62135596800,"objectID":"598b63dd58b43bce02403646f240cd3c","permalink":"https://weilongzheng.github.io/author/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/admin/","section":"author","summary":"Always looking for highly-motivated students and postdocs to join our team to work on understanding how the brain works! Feel free to email me if you are interested!\nHi, I am currently a Tenured-Track Associate Professor in Department of Computer Science and Engineering, Shanghai Jiao Tong University. My lab is Center for Brain-like Computing and Machine Intelligence (BCMI). My research interests cover the broad areas of affective brain-computer interfaces, computational neuroscience, machine learning, AI, clinical healthcare, and biomedical engineering.","tags":null,"title":"","type":"author"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":-62135596800,"objectID":"d41d8cd98f00b204e9800998ecf8427e","permalink":"https://weilongzheng.github.io/author/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/","section":"author","summary":"","tags":null,"title":"Authors","type":"author"},{"authors":["Yiting Wang","Jia-Wen Liu","Bao-Liang Lu","**Wei-Long Zheng**"],"categories":null,"content":"","date":1735574400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1735574400,"objectID":"66bbda21c8cf0cd7839512a19d42e4e6","permalink":"https://weilongzheng.github.io/publication/wang2024eeg/","publishdate":"2024-12-31T00:00:00+08:00","relpermalink":"/publication/wang2024eeg/","section":"publication","summary":"","tags":[],"title":"From EEG to Eye Movements: Cross-modal Emotion Recognition Using Constrained Adversarial Network with Dual Attention","type":"publication"},{"authors":null,"categories":null,"content":"","date":1735315200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1735315200,"objectID":"0da23455094b0b1752db221bc7f78ce2","permalink":"https://weilongzheng.github.io/datasets/seed-dv/","publishdate":"2024-12-28T00:00:00+08:00","relpermalink":"/datasets/seed-dv/","section":"datasets","summary":"We build a new dataset SEED-DV, recording 20 subjects EEG data when viewing 1400 video clips of 40 concepts for dynamic visual perception decoding.","tags":[],"title":"SEED-DV","type":"datasets"},{"authors":null,"categories":null,"content":"","date":1735228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1735228800,"objectID":"3b98187caa1f15dd880788efc3fba330","permalink":"https://weilongzheng.github.io/datasets/seed-vii/","publishdate":"2024-12-27T00:00:00+08:00","relpermalink":"/datasets/seed-vii/","section":"datasets","summary":"SJTU Emotion EEG Dataset (SEED) of seven emotions: positive, neutral, negative, disgust, fear, surprise, and anger.","tags":[],"title":"SEED-VII","type":"datasets"},{"authors":["Mingyu Gou","Ying-Jie Zhang","Ren-Jie Dai","Hao-Long Yin","Tianzhen Chen","Fei Cheng","Bao-Liang Lu","Jiang Du","**Wei-Long Zheng**"],"categories":null,"content":"","date":1733155200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1733155200,"objectID":"de1a4d996a7c43e47e71efe28416bf84","permalink":"https://weilongzheng.github.io/publication/gou2024addressing/","publishdate":"2024-12-03T00:00:00+08:00","relpermalink":"/publication/gou2024addressing/","section":"publication","summary":"","tags":[],"title":"Addressing Temporal and Auditory Factors in Meditative EEG with Self-Supervised Learning","type":"publication"},{"authors":["Tian-Fang Ma","Xuan-Hao Liu","**Wei-Long Zheng**","Bao-liang Lu"],"categories":null,"content":"","date":1733155200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1733155200,"objectID":"fd8b431250490f8d6920122b9529b976","permalink":"https://weilongzheng.github.io/publication/ma2024emotion/","publishdate":"2024-12-03T00:00:00+08:00","relpermalink":"/publication/ma2024emotion/","section":"publication","summary":"","tags":[],"title":"Emotion Recognition from Eye Movements Using Multi-way Autoregressive Model","type":"publication"},{"authors":["Xuan-Hao Liu","Wei-Bang Jiang","**Wei-Long Zheng**","Bao-liang Lu"],"categories":null,"content":"","date":1733155200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1733155200,"objectID":"842063bcffb2e5995898bd26ee568732","permalink":"https://weilongzheng.github.io/publication/liu2024moge/","publishdate":"2024-12-03T00:00:00+08:00","relpermalink":"/publication/liu2024moge/","section":"publication","summary":"","tags":[],"title":"MoGE: Mixture of Graph Experts for Cross-subject Emotion Recognition via Decomposing EEG","type":"publication"},{"authors":["Wen-Ding Li","Keya Hu","Carter Larsen","Yuqing Wu","Simon Alford","Caleb Woo","Spencer M Dunn","Hao Tang","Michelangelo Naim","Dat Nguyen","**Wei-Long Zheng**","Zenna Tavares","Yewen Pu","Kevin Ellis"],"categories":null,"content":"","date":1730649600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1730649600,"objectID":"ef9b8985035a3b6053f41e51f2d61049","permalink":"https://weilongzheng.github.io/publication/li2024combining/","publishdate":"2024-11-04T00:00:00+08:00","relpermalink":"/publication/li2024combining/","section":"publication","summary":"","tags":[],"title":"Combining induction and transduction for abstract reasoning","type":"publication"},{"authors":["Wei-Bang Jiang","Xuan-Hao Liu","**Wei-Long Zheng**","Bao-Liang Lu"],"categories":null,"content":"","date":1729612800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1729612800,"objectID":"12852fcdb75dc94d5d5a847f7dd3d895","permalink":"https://weilongzheng.github.io/publication/jiang2024seed/","publishdate":"2024-10-23T00:00:00+08:00","relpermalink":"/publication/jiang2024seed/","section":"publication","summary":"","tags":[],"title":"SEED-VII: A Multimodal Dataset of Six Basic Emotions with Continuous Labels for Emotion Recognition","type":"publication"},{"authors":["Xuan-Hao Liu","Xinhao Song","Dexuan He","Bao-Liang Lu","**Wei-Long Zheng**"],"categories":null,"content":"","date":1727625600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1727625600,"objectID":"da4cfd207e09e8c67e97ff47eb92fe62","permalink":"https://weilongzheng.github.io/publication/liu2024professor/","publishdate":"2024-09-30T00:00:00+08:00","relpermalink":"/publication/liu2024professor/","section":"publication","summary":"","tags":[],"title":"Professor X: Manipulating EEG BCI with Invisible and Robust Backdoor Attack","type":"publication"},{"authors":["**Wei-Long Zheng**","Zhongxuan Wu","Ali Hummos","Guangyu Robert Yang","Michael M Halassa"],"categories":null,"content":"","date":1727366400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1727366400,"objectID":"4daeed476acfed253ce53ddee2702ab1","permalink":"https://weilongzheng.github.io/publication/zheng2024rapid/","publishdate":"2024-09-27T00:00:00+08:00","relpermalink":"/publication/zheng2024rapid/","section":"publication","summary":"Cognitive flexibility is a fundamental ability that enables humans and animals to exhibit appropriate behaviors in various contexts. The thalamocortical interactions between the prefrontal cortex (PFC) and the mediodorsal thalamus (MD) have been identified as crucial for inferring temporal context, a critical component of cognitive flexibility. However, the neural mechanism responsible for context inference remains unknown. To address this issue, we propose a PFC-MD neural circuit model that utilizes a Hebbian plasticity rule to support rapid, online context inference. Specifically, the model MD thalamus can infer temporal contexts from prefrontal inputs within a few trials. This is achieved through the use of PFC-to-MD synaptic plasticity with pre-synaptic traces and adaptive thresholding, along with winner-take-all normalization in the MD. Furthermore, our model thalamus gates context-irrelevant neurons in the PFC, thus facilitating continual learning. We evaluate our model performance by having it sequentially learn various cognitive tasks. Incorporating an MD-like component alleviates catastrophic forgetting of previously learned contexts and demonstrates the transfer of knowledge to future contexts. Our work provides insight into how biological properties of thalamocortical circuits can be leveraged to achieve rapid context inference and continual learning.","tags":[],"title":"Rapid context inference in a thalamocortical model using recurrent neural networks","type":"publication"},{"authors":["Hao Tang","Keya Hu","Jin Peng Zhou","Si Cheng Zhong","**Wei-Long Zheng**","Xujie Si","Kevin Ellis"],"categories":null,"content":"","date":1727280000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1727280000,"objectID":"3f41981ea48ed94bbd4025c6d4a4582b","permalink":"https://weilongzheng.github.io/publication/tang2024code/","publishdate":"2024-09-26T00:00:00+08:00","relpermalink":"/publication/tang2024code/","section":"publication","summary":"","tags":[],"title":"Code Repair with LLMs gives an Exploration-Exploitation Tradeoff","type":"publication"},{"authors":["Xuanhao Liu","Yan-Kai Liu","Yansen Wang","Kan Ren","Hanwen Shi","Zilong Wang","Dongsheng Li","Bao-liang Lu","**Wei-Long Zheng**"],"categories":null,"content":"","date":1727280000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1727280000,"objectID":"c97370c1ab8cbab2c3d1b575439cee9f","permalink":"https://weilongzheng.github.io/publication/liueeg2video/","publishdate":"2024-09-26T00:00:00+08:00","relpermalink":"/publication/liueeg2video/","section":"publication","summary":"","tags":[],"title":"EEG2Video: Towards Decoding Dynamic Visual Perception from EEG Signals","type":"publication"},{"authors":["Zheng Yu","Yaohua Wang","Siying Cui","Aixi Zhang","**Wei-Long Zheng**","Senzhang Wang"],"categories":null,"content":"","date":1727280000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1727280000,"objectID":"9e98c8f4e8770a2ca359f4d489fa760e","permalink":"https://weilongzheng.github.io/publication/yu2024fuseanypart/","publishdate":"2024-09-26T00:00:00+08:00","relpermalink":"/publication/yu2024fuseanypart/","section":"publication","summary":"","tags":[],"title":"FuseAnyPart: Diffusion-Driven Facial Parts Swapping via Multiple Reference Images","type":"publication"},{"authors":["Shawn Shivdat","Tiange Zhan","Alessandro De Palma","**Wei-Long Zheng**","Parimala Krishnamurthy","Ezhil Paneerselvam","Samuel Snider","Matthew Bevers","Una-May O’Reilly","Jong Woo Lee","M Brandon Westover","Edilberto Amorim"],"categories":null,"content":"","date":1721750400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1721750400,"objectID":"0beecb58a0b7e47cb0f2d60621390c3f","permalink":"https://weilongzheng.github.io/publication/shivdat2024early/","publishdate":"2024-07-24T00:00:00+08:00","relpermalink":"/publication/shivdat2024early/","section":"publication","summary":"","tags":[],"title":"Early burst suppression similarity association with structural brain injury severity on MRI after cardiac arrest","type":"publication"},{"authors":["Khin Pa Pa Aung","Hao-Long Yin","Tian-Fang Ma","**Wei-Long Zheng**","Bao-Liang Lu"],"categories":null,"content":"","date":1720972800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1720972800,"objectID":"062ff5525005c47d0e1910d3e55d0386","permalink":"https://weilongzheng.github.io/publication/aung2024multimodal/","publishdate":"2024-07-15T00:00:00+08:00","relpermalink":"/publication/aung2024multimodal/","section":"publication","summary":"","tags":[],"title":"A Multimodal Myanmar Emotion Dataset for Emotion Recognition","type":"publication"},{"authors":["Keya Hu","Ren-Jie Dai","Wen-Tao Chen","Hao-Long Yin","Bao-Liang Lu","**Wei-Long Zheng**"],"categories":null,"content":"","date":1720972800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1720972800,"objectID":"781a19f0891fd36547df3a2d28351501","permalink":"https://weilongzheng.github.io/publication/hu2024contrastive/","publishdate":"2024-07-15T00:00:00+08:00","relpermalink":"/publication/hu2024contrastive/","section":"publication","summary":"","tags":[],"title":"Contrastive Self-supervised EEG Representation Learning for Emotion Classification","type":"publication"},{"authors":["Yi-Dong Zhao","Yan-Kai Liu","**Wei-Long Zheng**","Bao-Liang Lu"],"categories":null,"content":"","date":1720972800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1720972800,"objectID":"51b94209ec466924f6c0139ff1b8a503","permalink":"https://weilongzheng.github.io/publication/zhao2024eeg/","publishdate":"2024-07-15T00:00:00+08:00","relpermalink":"/publication/zhao2024eeg/","section":"publication","summary":"","tags":[],"title":"EEG Data Augmentation for Emotion Recognition Using Diffusion Model","type":"publication"},{"authors":["Wei Gu","Yun-Huan Li","Li-Ming Zhao","**Wei-Long Zheng**","Bao-Liang Lu"],"categories":null,"content":"","date":1720972800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1720972800,"objectID":"aea75c03c11f73e46c4e4567c7fde66b","permalink":"https://weilongzheng.github.io/publication/gu2024eeg/","publishdate":"2024-07-15T00:00:00+08:00","relpermalink":"/publication/gu2024eeg/","section":"publication","summary":"","tags":[],"title":"EEG-Based Tension Recognition Annotated with Electrodermal Activity","type":"publication"},{"authors":["Tian-Hua Li","Tian-Fang Ma","Dan Peng","**Wei-Long Zheng**","Bao-Liang Lu"],"categories":null,"content":"","date":1720972800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1720972800,"objectID":"5b98a5eba7b0db900e782a5a383b1db3","permalink":"https://weilongzheng.github.io/publication/li2024focused/","publishdate":"2024-07-15T00:00:00+08:00","relpermalink":"/publication/li2024focused/","section":"publication","summary":"","tags":[],"title":"Focused State Recognition Using EEG with Eye Movement-Assisted Annotation","type":"publication"},{"authors":["Haowei Cui","Hanwen Shi","Bao-Liang Lu","**Wei-Long Zheng**"],"categories":null,"content":"","date":1720972800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1720972800,"objectID":"d27a3528e13c39176cdbff1cb84d611b","permalink":"https://weilongzheng.github.io/publication/cui2024improving/","publishdate":"2024-07-15T00:00:00+08:00","relpermalink":"/publication/cui2024improving/","section":"publication","summary":"","tags":[],"title":"Improving Cross-Subject Emotion Recognition Performance with an Encoder-Decoder Structure","type":"publication"},{"authors":["Mingyu Gou","Hao-Long Yin","Bao-Liang Lu","**Wei-Long Zheng**"],"categories":null,"content":"","date":1720972800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1720972800,"objectID":"dfc7cae5536d673326c4c28a3d15d559","permalink":"https://weilongzheng.github.io/publication/gou2024multi/","publishdate":"2024-07-15T00:00:00+08:00","relpermalink":"/publication/gou2024multi/","section":"publication","summary":"","tags":[],"title":"Multi-modal Adversarial Regressive Transformer for Cross-subject Fatigue Detection","type":"publication"},{"authors":["Tian-Fang Ma","Lu-Yu Liu","Li-Ming Zhao","Dan Peng","Yong Lu","**Wei-Long Zheng**","Bao-Liang Lu"],"categories":null,"content":"","date":1719676800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1719676800,"objectID":"b826fad26a7112656b8933222b3c3cee","permalink":"https://weilongzheng.github.io/publication/ma2024detecting/","publishdate":"2024-06-30T00:00:00+08:00","relpermalink":"/publication/ma2024detecting/","section":"publication","summary":"","tags":[],"title":"Detecting Major Depression Disorder with Multiview Eye Movement Features in a Novel Oil Painting Paradigm","type":"publication"},{"authors":["Yu-Ting Lan","Wei-Bang Jiang","**Wei-Long Zheng**","Bao-Liang Lu"],"categories":null,"content":"","date":1713024000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1713024000,"objectID":"88eee68b0422cae37cfa46fcd66df4be","permalink":"https://weilongzheng.github.io/publication/lan2024cemoae/","publishdate":"2024-04-14T00:00:00+08:00","relpermalink":"/publication/lan2024cemoae/","section":"publication","summary":"","tags":[],"title":"CEMOAE: A Dynamic Autoencoder with Masked Channel Modeling for Robust EEG-Based Emotion Recognition","type":"publication"},{"authors":["Wei-Bang Jiang","Ziyi Li","**Wei-Long Zheng**","Bao-Liang Lu"],"categories":null,"content":"","date":1713024000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1713024000,"objectID":"5d9af257b98fe8715ea3ab12f5e1a0b5","permalink":"https://weilongzheng.github.io/publication/jiang2024functional/","publishdate":"2024-04-14T00:00:00+08:00","relpermalink":"/publication/jiang2024functional/","section":"publication","summary":"","tags":[],"title":"Functional emotion transformer for EEG-assisted cross-modal emotion recognition","type":"publication"},{"authors":["Pengxuan Gao","Tianyu Liu","Jia-Wen Liu","Bao-Liang Lu","**Wei-Long Zheng**"],"categories":null,"content":"","date":1713024000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1713024000,"objectID":"bc598e6c7e237688ae98932db2f4714b","permalink":"https://weilongzheng.github.io/publication/gao2024multimodal/","publishdate":"2024-04-14T00:00:00+08:00","relpermalink":"/publication/gao2024multimodal/","section":"publication","summary":"","tags":[],"title":"Multimodal Multi-View Spectral-Spatial-Temporal Masked Autoencoder for Self-Supervised Emotion Recognition","type":"publication"},{"authors":["Ziyi Li","Li-Ming Zhao","**Wei-Long Zheng**","Bao-Liang Lu"],"categories":null,"content":"","date":1713024000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1713024000,"objectID":"7c613a9e2faa5483ca9d24338045d880","permalink":"https://weilongzheng.github.io/publication/li2024temporal/","publishdate":"2024-04-14T00:00:00+08:00","relpermalink":"/publication/li2024temporal/","section":"publication","summary":"","tags":[],"title":"Temporal-Spatial Prediction: Pre-Training on Diverse Datasets for EEG Classification","type":"publication"},{"authors":["Jing-Yi Liu","Jia-Wen Liu","**Wei-Long Zheng**","Bao-Liang Lu"],"categories":null,"content":"","date":1701705600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1701705600,"objectID":"c00f647ba4171a99fd5da51186a181aa","permalink":"https://weilongzheng.github.io/publication/liu2023transformer/","publishdate":"2023-12-05T00:00:00+08:00","relpermalink":"/publication/liu2023transformer/","section":"publication","summary":"","tags":[],"title":"Transformer-Based Domain Adaptation for Multi-Modal Emotion Recognition in Response to Game Animation Videos","type":"publication"},{"authors":["Edilberto Amorim","**Wei-Long Zheng**","Mohammad M Ghassemi","Mahsa Aghaeeaval","Pravinkumar Kandhare","Vishnu Karukonda","Jong Woo Lee","Susan T Herman","Adithya Sivaraju","Nicolas Gaspard","Jeannette Hofmeijer","Michel JAM Van Putten","Reza Sameni","Matthew A Reyna","Gari D Clifford","M Brandon Westover"],"categories":null,"content":"","date":1701360000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1701360000,"objectID":"6df55c247d94733222dfa384625bca8a","permalink":"https://weilongzheng.github.io/publication/amorim2023international/","publishdate":"2023-12-01T00:00:00+08:00","relpermalink":"/publication/amorim2023international/","section":"publication","summary":"","tags":[],"title":"Identifying sex differences in EEG-based emotion recognition using graph convolutional network with attention mechanism","type":"publication"},{"authors":["Dan Peng","**Wei-Long Zheng**","Luyu Liu","Wei-Bang Jiang","Ziyi Li","Yong Lu","Bao-Liang Lu"],"categories":null,"content":"","date":1700496000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1700496000,"objectID":"ff052b8d3d58b60fc71b73f32ab503e8","permalink":"https://weilongzheng.github.io/publication/peng2023identifying/","publishdate":"2023-11-21T00:00:00+08:00","relpermalink":"/publication/peng2023identifying/","section":"publication","summary":"","tags":[],"title":"Identifying sex differences in EEG-based emotion recognition using graph convolutional network with attention mechanism","type":"publication"},{"authors":["Zhong-Wei Jin","Jia-Wen Liu","**Wei-Long Zheng**","Bao-Liang Lu"],"categories":null,"content":"","date":1700409600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1700409600,"objectID":"9b88e69630affc564b857106ab8d2536","permalink":"https://weilongzheng.github.io/publication/jin2023daformer/","publishdate":"2023-11-20T00:00:00+08:00","relpermalink":"/publication/jin2023daformer/","section":"publication","summary":"","tags":[],"title":"DAformer: Transformer with Domain Adversarial Adaptation for EEG-Based Emotion Recognition with Live-Oil Paintings","type":"publication"},{"authors":["Jian-Ming Zhang","Jiawen Liu","Ziyi Li","Tian-Fang Ma","Yiting Wang","**Wei-Long Zheng**","Bao-Liang Lu"],"categories":null,"content":"","date":1700064000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1700064000,"objectID":"77eeffe2d80807336d51dd36a14bb2d0","permalink":"https://weilongzheng.github.io/publication/zhang2023naturalistic/","publishdate":"2023-11-16T00:00:00+08:00","relpermalink":"/publication/zhang2023naturalistic/","section":"publication","summary":"","tags":[],"title":"Naturalistic Emotion Recognition Using EEG and Eye Movements","type":"publication"},{"authors":["Xuan-Hao Liu","Wei-Bang Jiang","**Wei-Long Zheng**","Bao-Liang Lu"],"categories":null,"content":"","date":1700064000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1700064000,"objectID":"f9c1be4413333d9ba69f2636ed823545","permalink":"https://weilongzheng.github.io/publication/liu2023two/","publishdate":"2023-11-16T00:00:00+08:00","relpermalink":"/publication/liu2023two/","section":"publication","summary":"","tags":[],"title":"Two-Stream Spectral-Temporal Denoising Network for End-to-End Robust EEG-Based Emotion Recognition","type":"publication"},{"authors":["Dan Peng","Wei Liu","Yun Luo","Ziyu Mao","**Wei-Long Zheng**","Bao-Liang Lu"],"categories":null,"content":"","date":1690128000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1690128000,"objectID":"c2bcc6a63d6595483176dc4326590bdf","permalink":"https://weilongzheng.github.io/publication/lan2023investigating/","publishdate":"2023-07-24T00:00:00+08:00","relpermalink":"/publication/lan2023investigating/","section":"publication","summary":"","tags":[],"title":"Deep Depression Detection with Resting-State and Cognitive-Task EEG","type":"publication"},{"authors":["Yu-Ting Lan","Dan Peng","Wei Liu","Yun Luo","Ziyu Mao","**Wei-Long Zheng**","Bao-Liang Lu"],"categories":null,"content":"","date":1690128000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1690128000,"objectID":"648a24a06f67fb5331450defed4e0985","permalink":"https://weilongzheng.github.io/publication/peng2023deep/","publishdate":"2023-07-24T00:00:00+08:00","relpermalink":"/publication/peng2023deep/","section":"publication","summary":"","tags":[],"title":"Investigating emotion EEG patterns for depression detection with attentive simple graph convolutional network","type":"publication"},{"authors":["Wei-Bang Jiang","Xuan-Hao Liu","**Wei-Long Zheng**","Bao-Liang Lu"],"categories":null,"content":"","date":1690128000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1690128000,"objectID":"8ef3d40b2784cf1991dcb798672e15e7","permalink":"https://weilongzheng.github.io/publication/jiang2023multimodal/","publishdate":"2023-07-24T00:00:00+08:00","relpermalink":"/publication/jiang2023multimodal/","section":"publication","summary":"","tags":[],"title":"Multimodal adaptive emotion transformer with flexible modality inputs on a novel dataset with continuous labels","type":"publication"},{"authors":["Luyu Liu“, ”Dan Peng","**Wei-Long Zheng**","Bao-Liang Lu"],"categories":null,"content":"","date":1690128000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1690128000,"objectID":"7806eaf7fbc7eb08997b358851c6fd56","permalink":"https://weilongzheng.github.io/publication/liu2023objective/","publishdate":"2023-07-24T00:00:00+08:00","relpermalink":"/publication/liu2023objective/","section":"publication","summary":"","tags":[],"title":"Objective Depression Detection Using EEG and Eye Movement Signals Induced by Oil Paintings","type":"publication"},{"authors":["Rong-Fei Gu“, ”Li-Ming Zhao","**Wei-Long Zheng**","Bao-Liang Lu"],"categories":null,"content":"","date":1690128000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1690128000,"objectID":"4b3065ff4e72adb99ba5b53c09e45db6","permalink":"https://weilongzheng.github.io/publication/gu2023tagging/","publishdate":"2023-07-24T00:00:00+08:00","relpermalink":"/publication/gu2023tagging/","section":"publication","summary":"","tags":[],"title":"Tagging Continuous Labels for EEG-based Emotion Classification","type":"publication"},{"authors":["Edilberto Amorim","**Wei-Long Zheng**","Jin Jing","Mohammad M Ghassemi","Jong Woo Lee","Ona Wu","Susan T Herman","Trudy Pang","Adithya Sivaraju","Nicolas Gaspard","Lawrence Hirsch","Barry J Ruijter","Marleen C Tjepkema-Cloostermans","Jeannette Hofmeijer","Michel JAM van Putten","M Brandon Westover"],"categories":null,"content":"","date":1688572800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1688572800,"objectID":"57fc70ed93edc888ec5cc6ee2e1b231d","permalink":"https://weilongzheng.github.io/publication/amorim2023neurophysiology/","publishdate":"2023-07-06T00:00:00+08:00","relpermalink":"/publication/amorim2023neurophysiology/","section":"publication","summary":"","tags":[],"title":"Neurophysiology State Dynamics Underlying Acute Neurological Recovery After Cardiac Arrest","type":"publication"},{"authors":["Yu-Ting Lan","Kan Ren","Yansen Wang","**Wei-Long Zheng**","Dongsheng Li","Bao-Liang Lu","Lili Qiu"],"categories":null,"content":"","date":1688572800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1688572800,"objectID":"ad76fa74b1072bb8cdf3bec296af9db7","permalink":"https://weilongzheng.github.io/publication/lan2023seeing/","publishdate":"2023-07-06T00:00:00+08:00","relpermalink":"/publication/lan2023seeing/","section":"publication","summary":"","tags":[],"title":"Seeing through the Brain: Image Reconstruction of Visual Perception from Human Brain Signals","type":"publication"},{"authors":["Rong-Fei Gu","Rui Li","**Wei-Long Zheng**","Bao-Liang Lu"],"categories":null,"content":"","date":1687017600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1687017600,"objectID":"db12791f8968d45ee06916ef7e6f2483","permalink":"https://weilongzheng.github.io/publication/gu2023cross/","publishdate":"2023-06-18T00:00:00+08:00","relpermalink":"/publication/gu2023cross/","section":"publication","summary":"","tags":[],"title":"Cross-Subject Decision Confidence Estimation from EEG Signals Using Spectral-Spatial-Temporal Adaptive GCN with Domain Adaptation","type":"publication"},{"authors":null,"categories":null,"content":"","date":1686844800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1686844800,"objectID":"e9249b5f7223e2239f83f9da25d1ab84","permalink":"https://weilongzheng.github.io/datasets/icare/","publishdate":"2023-06-16T00:00:00+08:00","relpermalink":"/datasets/icare/","section":"datasets","summary":"I-CARE: International Cardiac Arrest REsearch consortium Database for Predicting Neurological Recovery from Coma After Cardiac Arrest.","tags":[],"title":"I-CARE","type":"datasets"},{"authors":["Jinbu Tang","Wei Zhou","**Wei-Long Zheng**","Zheng Zeng","Jiayi Li","Ruizhi Su","Tuheti Adili","Wei Chen","Chen Chen","Jingchun Luo"],"categories":null,"content":"","date":1685808000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1685808000,"objectID":"c07944cb7ea58eed1a737dd838299e2a","permalink":"https://weilongzheng.github.io/publication/tang2024attention/","publishdate":"2023-06-04T00:00:00+08:00","relpermalink":"/publication/tang2024attention/","section":"publication","summary":"","tags":[],"title":"Attention-Guided Multi-scale Convolutional Neural Network for Driving Fatigue Detection","type":"publication"},{"authors":["Wei-Bang Jiang","Xu Yan","**Wei-Long Zheng**","Bao-Liang Lu"],"categories":null,"content":"","date":1685808000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1685808000,"objectID":"b3151c7430c35f02a3923322dc119acc","permalink":"https://weilongzheng.github.io/publication/jiang2023elastic/","publishdate":"2023-06-04T00:00:00+08:00","relpermalink":"/publication/jiang2023elastic/","section":"publication","summary":"","tags":[],"title":"Elastic Graph Transformer Networks for EEG-Based Emotion Recognition","type":"publication"},{"authors":null,"categories":null,"content":"","date":1682524800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1682524800,"objectID":"3b3a53ae7d1c7e3081be98a3d7ee332d","permalink":"https://weilongzheng.github.io/project/emotion/","publishdate":"2023-04-27T00:00:00+08:00","relpermalink":"/project/emotion/","section":"project","summary":"Multimodal emotion recognition using EEG and eye movements.","tags":[],"title":"Affective Brain-Comouter Interactions","type":"project"},{"authors":["Cheng Fei","Rui Li","Li-Ming Zhao","**Wei-Long Zheng**","Bao-Liang Lu"],"categories":null,"content":"","date":1682265600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1682265600,"objectID":"f9261cf0195a6d834ed0ef6342c99d3c","permalink":"https://weilongzheng.github.io/publication/fei2023eeg/","publishdate":"2023-04-24T00:00:00+08:00","relpermalink":"/publication/fei2023eeg/","section":"publication","summary":"","tags":[],"title":"EEG-Eye Movements Cross-Modal Decision Confidence Measurement with Generative Adversarial Networks","type":"publication"},{"authors":["Yu-Ting Lan","Ze-Chen Li","Dan Peng","**Wei-Long Zheng**","Bao-Liang Lu"],"categories":null,"content":"","date":1682092800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1682092800,"objectID":"b04b3212d92f603d9fe414e6dec49d3d","permalink":"https://weilongzheng.github.io/publication/lan2023identifying/","publishdate":"2023-04-22T00:00:00+08:00","relpermalink":"/publication/lan2023identifying/","section":"publication","summary":"","tags":[],"title":"Identifying Artistic Expertise Difference in Emotion Recognition in Response to Oil Paintings","type":"publication"},{"authors":["Tian-Fang Ma","**Wei-Long Zheng**","Bao-Liang Lu"],"categories":null,"content":"","date":1669046400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1669046400,"objectID":"768fc17354868a6c4cc5238bc416e40d","permalink":"https://weilongzheng.github.io/publication/ma2022few/","publishdate":"2022-11-22T00:00:00+08:00","relpermalink":"/publication/ma2022few/","section":"publication","summary":"","tags":[],"title":"Few-Shot Class-Incremental Learning for EEG-Based Emotion Recognition","type":"publication"},{"authors":["**Wei-Long Zheng**","Jennifer A Kim","Jonathan Elmer","Sahar F Zafar","Manohar Ghanta","Valdery Moura Junior","Aman Patel","Eric Rosenthal","M Brandon Westover"],"categories":null,"content":"","date":1667232000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1667232000,"objectID":"bf9ee52b8619c0cbfcc4eb9757cc1295","permalink":"https://weilongzheng.github.io/publication/zheng2022automated/","publishdate":"2022-11-01T00:00:00+08:00","relpermalink":"/publication/zheng2022automated/","section":"publication","summary":"","tags":[],"title":"Automated EEG-based prediction of delayed cerebral ischemia after subarachnoid hemorrhage","type":"publication"},{"authors":["Rui Li","Yiting Wang","**Wei-Long Zheng**","Bao-Liang Lu"],"categories":null,"content":"","date":1665331200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1665331200,"objectID":"fa2924dd542aba57f363594e06231a8f","permalink":"https://weilongzheng.github.io/publication/li2022multi/","publishdate":"2022-10-10T00:00:00+08:00","relpermalink":"/publication/li2022multi/","section":"publication","summary":"","tags":[],"title":"A Multi-view Spectral-Spatial-Temporal Masked Autoencoder for Decoding Emotions with Self-supervised Learning","type":"publication"},{"authors":["Jennifer A Kim","**Wei-Long Zheng**","Jonathan Elmer","Jin Jing","Sahar F Zafar","Manohar Ghanta","Valdery Moura Junior","Emily J Gilmore","Lawrence J Hirsch","Aman Patel","Eric Rosenthal","M Brandon Westover"],"categories":null,"content":"","date":1661961600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1661961600,"objectID":"e8f0420d1011fa447cce84a14b201da8","permalink":"https://weilongzheng.github.io/publication/kim2022high/","publishdate":"2022-09-01T00:00:00+08:00","relpermalink":"/publication/kim2022high/","section":"publication","summary":"","tags":[],"title":"High epileptiform discharge burden predicts delayed cerebral ischemia after subarachnoid hemorrhage","type":"publication"},{"authors":["Edilberto Amorim","Marcos S Firme","**Wei-Long Zheng**","Kenneth T Shelton","Oluwaseun Akeju","Gaston Cudemus","Raz Yuval","M Brandon Westover"],"categories":null,"content":"","date":1659283200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1659283200,"objectID":"3e7cd3d5fd247cd096b82718e10cd8b9","permalink":"https://weilongzheng.github.io/publication/amorim2022high/","publishdate":"2022-08-01T00:00:00+08:00","relpermalink":"/publication/amorim2022high/","section":"publication","summary":"","tags":[],"title":"High incidence of epileptiform activity in adults undergoing extracorporeal membrane oxygenation","type":"publication"},{"authors":["Shuai Luo","Yu-Ting Lan","Dan Peng","Ziyi Li","**Wei-Long Zheng**","Bao-Liang Lu"],"categories":null,"content":"","date":1657814400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1657814400,"objectID":"48189135b2991f2a5c6f3890d16359e6","permalink":"https://weilongzheng.github.io/publication/luo2022multimodal/","publishdate":"2022-07-15T00:00:00+08:00","relpermalink":"/publication/luo2022multimodal/","section":"publication","summary":"","tags":[],"title":"Multimodal emotion recognition in response to oil paintings","type":"publication"},{"authors":["Nitish M Harid","Jin Jing","Jacob Hogan","Fábio A. Nascimento","An Ouyang","**Wei-Long Zheng**","Wendong Ge","Sahar F. Zafar","Jennifer A. Kim","D. Lam Alice","Aline Herlopian","Douglas Maus","Ioannis Karakis","Marcus Ng","Shenda Hong","Zhu Yu","Peter W. Kaplan","Sydney Cash","Mouhsin Shafi","Gabriel Martz","Jonathan J. Halford","Michael Brandon Westover"],"categories":null,"content":"","date":1655222400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1655222400,"objectID":"e36777d6002e77043d266dba0ab32a93","permalink":"https://weilongzheng.github.io/publication/harid2022measuring/","publishdate":"2022-06-15T00:00:00+08:00","relpermalink":"/publication/harid2022measuring/","section":"publication","summary":"","tags":[],"title":"Measuring expertise in identifying interictal epileptiform discharges","type":"publication"},{"authors":["Wei Liu","**Wei-Long Zheng**","Ziyi Li","Si-Yuan Wu","Lu Gan","Bao-Liang Lu"],"categories":null,"content":"","date":1648396800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1648396800,"objectID":"a5228ff5ef3e952fc4e39731480d7a3d","permalink":"https://weilongzheng.github.io/publication/liu2022identifying/","publishdate":"2022-03-28T00:00:00+08:00","relpermalink":"/publication/liu2022identifying/","section":"publication","summary":"","tags":[],"title":"Identifying similarities and differences in emotion recognition with EEG and eye movements among Chinese, German, and French People","type":"publication"},{"authors":["Xun Wu","**Wei-Long Zheng**","Ziyi Li","Bao-Liang Lu"],"categories":null,"content":"","date":1643558400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1643558400,"objectID":"7b35b0f6aef2903796c83c8aabcc0da5","permalink":"https://weilongzheng.github.io/publication/wu2022investigating/","publishdate":"2022-01-31T00:00:00+08:00","relpermalink":"/publication/wu2022investigating/","section":"publication","summary":"","tags":[],"title":"Investigating EEG-based functional connectivity patterns for multimodal emotion recognition","type":"publication"},{"authors":["**Wei-Long Zheng***","Edilberto Amorim*","Jin Jing","Ona Wu","Mohammad Ghassemi","Jong Woo Lee","Adithya Sivaraju","Trudy Pang","Susan T. Herman","Nicolas Gaspard","Barry J. Ruijter","Marleen C. Tjepkema-Cloostermans","Jeannette Hofmeijer","Michel J.A.M. van Putten","M. Brandon Westover"],"categories":null,"content":"","date":1640620800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1640620800,"objectID":"c085548e694b555df81678302a151d09","permalink":"https://weilongzheng.github.io/publication/zheng2021predicting2/","publishdate":"2021-12-28T00:00:00+08:00","relpermalink":"/publication/zheng2021predicting2/","section":"publication","summary":"Objective: Most cardiac arrest patients who are successfully resuscitated are initially comatose due to hypoxic-ischemic brain injury. Quantitative electroencephalography (EEG) provides valuable prognostic information. However, prior approaches largely rely on snapshots of the EEG, without taking advantage of temporal information. Methods: We present a recurrent deep neural network with the goal of capturing temporal dynamics from longitudinal EEG data to predict long-term neurological outcomes. We utilized a large international dataset of continuous EEG recordings from 1,038 cardiac arrest patients from seven hospitals in Europe and the US. Poor outcome was defined as a Cerebral Performance Category (CPC) score of 3-5, and good outcome as CPC score 0-2 at 3 to 6-months after cardiac arrest. Model performance is evaluated using 5-fold cross validation. Results: The proposed approach provides predictions which improve over time, beginning from an area under the receiver operating characteristic curve (AUC-ROC) of 0.78 (95% CI: 0.72-0.81) at 12 hours, and reaching 0.88 (95% CI: 0.85-0.91) by 66 h after cardiac arrest. At 66 h, (sensitivity, specificity) points of interest on the ROC curve for predicting poor outcomes were (32,99)%, (55,95)%, and (62,90)%, (99,23)%, (95,47)%, and (90,62)%; whereas for predicting good outcome, the corresponding operating points were (17,99)%, (47,95)%, (62,90)%, (99,19)%, (95,48)%, (70,90)%. Moreover, the model provides predicted probabilities that closely match the observed frequencies of good and poor outcomes (calibration error 0.04). Conclusions and significance: These findings suggest that accounting for EEG trend information can substantially improve prediction of neurologic outcomes for patients with coma following cardiac arrest. ","tags":[],"title":"Predicting Neurological Outcome from Electroencephalogram Dynamics in Comatose Patients after Cardiac Arrest with Deep Learning","type":"publication"},{"authors":["**Wei-Long Zheng***","Edilberto Amorim*","Jin Jing","Wendong Ge","Shenda Hong","Ona Wu","Mohammad Ghassemi","Jong Woo Lee","Adithya Sivaraju","Trudy Pang","Susan T. Herman","Nicolas Gaspard","Barry J. Ruijter","Jimeng Sun","Marleen C. Tjepkema-Cloostermans","Jeannette Hofmeijer","Michel J.A.M. van Putten","M. Brandon Westover"],"categories":null,"content":"","date":1634745600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1634745600,"objectID":"af1b3c497dc1ec3bb56e366d75999c14","permalink":"https://weilongzheng.github.io/publication/zheng2021predicting/","publishdate":"2021-10-21T00:00:00+08:00","relpermalink":"/publication/zheng2021predicting/","section":"publication","summary":"Objective Electroencephalography (EEG) is an important tool for neurological outcome prediction after cardiac arrest. However, the complexity of continuous EEG data limits timely and accurate interpretation by clinicians. We develop a deep neural network (DNN) model to leverage complex EEG trends for early and accurate assessment of cardiac arrest coma recovery likelihood. Methods We developed a multiscale DNN combining convolutional neural networks (CNN) and recurrent neural networks (long short-term memory [LSTM]) using EEG and demographic information (age, gender, shockable rhythm) from a multicenter cohort of 1,038 cardiac arrest patients. The CNN learns EEG feature representations while the multiscale LSTM captures short-term and long-term EEG dynamics on multiple time scales. Poor outcome is defined as a Cerebral Performance Category (CPC) score of 3-5 and good outcome as CPC score 1-2 at 3-6 months after cardiac arrest. Performance is evaluated using area under the receiver operating characteristic curve (AUC) and calibration error. Results Model performance increased with EEG duration, with AUC increasing from 0.83 (95% Confidence Interval [CI] 0.79-0.87 at 12h to 0.91 (95%CI 0.88-0.93) at 66h. Sensitivity of good and poor outcome prediction was 77% and 75% at a specificity of 90%, respectively. Sensitivity of poor outcome was 50% at a specificity of 99%. Predicted probability was well matched to the observation frequency of poor outcomes, with a calibration error of 0.11 [0.09-0.14]. Conclusions These results demonstrate that incorporating EEG evolution over time improves the accuracy of neurologic outcome prediction for patients with coma after cardiac arrest.","tags":[],"title":"Predicting Neurological Outcome in Comatose Patients after Cardiac Arrest with Multiscale Deep Neural Networks","type":"publication"},{"authors":null,"categories":null,"content":"","date":1619452800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1619452800,"objectID":"b915a8f84d37c317b263955766790e08","permalink":"https://weilongzheng.github.io/datasets/seed-v/","publishdate":"2021-04-27T00:00:00+08:00","relpermalink":"/datasets/seed-v/","section":"datasets","summary":"SJTU Emotion EEG Dataset (SEED-V) of five emotions: happy, sad, fear, disgust and neutral.","tags":[],"title":"SEED-V","type":"datasets"},{"authors":["Hsin Yi Chen","**Wei-Long Zheng**","Sahar Zafar","Jonathan Elmer","Manohar Ghanta","Valdery Moura Junior","Aman Patel","Eric Rosenthal","Emily Gilmore","M. Brandon Westover","Jennifer Kim"],"categories":null,"content":"","date":1618243200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1618243200,"objectID":"20c5c75ce8546727139f8a9669e53760","permalink":"https://weilongzheng.github.io/publication/chen2021machine/","publishdate":"2021-04-13T00:00:00+08:00","relpermalink":"/publication/chen2021machine/","section":"publication","summary":"","tags":[],"title":"A Machine Learning Algorithm for Predicting Outcome after Subarachnoid Hemorrhage","type":"publication"},{"authors":["Jennifer A. Kim","**Wei-Long Zheng**","Jonathan Elmer","Jin Jing","Sahar F. Zafar","Manohar Ghanta","Valdery Moura Junior","Emily J. Gilmore","Lawrence J. Hirsch","Aman Patel","Eric Rosenthal","M. Brandon Westover"],"categories":null,"content":"","date":1618070400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1618070400,"objectID":"d9c5aac509bde59b04af9429455d14a9","permalink":"https://weilongzheng.github.io/publication/kim2021high/","publishdate":"2021-04-11T00:00:00+08:00","relpermalink":"/publication/kim2021high/","section":"publication","summary":"Objective. To investigate whether epileptiform discharge burden can identify those at risk for delayed cerebral ischemia (DCI) after subarachnoid hemorrhage (SAH). Methods. Retrospective analysis of 113 moderate to severe grade SAH patients who had continuous EEG (cEEG) recordings during their hospitalization. We calculated the burden of epileptiform discharges (ED), measured as number of ED per hour. Results. We find that many SAH patients have an increase in ED burden during the first 3–10 days following rupture, the major risk period for DCI. However, those who develop DCI have a significantly higher hourly burden from days 3.5–6 after SAH vs. those who do not. ED burden is higher in DCI patients when assessed in relation to the onset of DCI (area under the receiver operator curve 0.72). Finally, specific trends of ED burden over time, assessed by group-based trajectory analysis, also help stratify DCI risk. Conclusions. These results suggest that ED burden is a useful parameter for identifying those at higher risk of developing DCI after SAH. The higher burden rate associated with DCI supports the theory of metabolic supply-demand mismatch which contributes to this complication. Significance. ED burden is a novel biomarker for predicting those at high risk of DCI.","tags":[],"title":"High epileptiform discharge burden predicts delayed cerebral ischemia after subarachnoid hemorrhage","type":"publication"},{"authors":["Wei Liu","Jie-Lin Qiu","**Wei-Long Zheng**","Bao-Liang Lu"],"categories":null,"content":"","date":1617552000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1617552000,"objectID":"cd7eed9812e2ed8b252e2b7b4880988f","permalink":"https://weilongzheng.github.io/publication/liu2021comparing/","publishdate":"2021-04-05T00:00:00+08:00","relpermalink":"/publication/liu2021comparing/","section":"publication","summary":"","tags":[],"title":"Comparing Recognition Performance and Robustness of Multimodal Deep Learning Models for Multimodal Emotion Recognition","type":"publication"},{"authors":null,"categories":null,"content":"","date":1617206400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1617206400,"objectID":"b5212ff14495335aecc0bf56f04a5957","permalink":"https://weilongzheng.github.io/project/thalamus/","publishdate":"2021-04-01T00:00:00+08:00","relpermalink":"/project/thalamus/","section":"project","summary":"Develop recurrent neural networks with a thalamus-like component and synaptic plasticity rules to model the thalamocortical interactions in cognitive flexibility.","tags":[],"title":"Building and Understanding the Brain","type":"project"},{"authors":null,"categories":null,"content":"","date":1609430400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609430400,"objectID":"e0620b5b2691eeabd7ec4c8d4c8a81f2","permalink":"https://weilongzheng.github.io/project/neurophysiology/","publishdate":"2021-01-01T00:00:00+08:00","relpermalink":"/project/neurophysiology/","section":"project","summary":"Continuous brain monitoring to identify neural dynamics and predict neuological outcomes for critically ill patients.","tags":[],"title":"Critical Care Neurophysiology","type":"project"},{"authors":["Wei Wu","Wei Sun","Q. M. Jonathan Wu","Yimin Yang","Hui Zhang","**Wei-Long Zheng**","Bao-Liang Lu"],"categories":null,"content":"","date":1602000000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1602000000,"objectID":"a33cd9d64682a94fc8a77d659134dd34","permalink":"https://weilongzheng.github.io/publication/wu2020multimodal/","publishdate":"2020-10-07T00:00:00+08:00","relpermalink":"/publication/wu2020multimodal/","section":"publication","summary":"The phenomenon of increasing accidents caused by reduced vigilance does exist. In the future, the high accuracy of vigilance estimation will play a significant role in public transportation safety. We propose a multimodal regression network that consists of multichannel deep autoencoders with subnetwork neurons (MCDAEsn). After we define two thresholds of ``0.35'' and ``0.70'' from the percentage of eye closure, the output values are in the continuous range of 0-0.35, 0.36-0.70, and 0.71-1 representing the awake state, the tired state, and the drowsy state, respectively. To verify the efficiency of our strategy, we first applied the proposed approach to a single modality. Then, for the multimodality, since the complementary information between forehead electrooculography and electroencephalography features, we found the performance of the proposed approach using features fusion significantly improved, demonstrating the effectiveness and efficiency of our method.","tags":[],"title":"Multimodal Vigilance Estimation Using Deep Learning","type":"publication"},{"authors":["Xun Wu","**Wei-Long Zheng**","Bao-Liang Lu"],"categories":null,"content":"","date":1585929600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1585929600,"objectID":"977bd4ed9503d988d68d72347df87786","permalink":"https://weilongzheng.github.io/publication/wu2020investigating/","publishdate":"2020-04-04T00:00:00+08:00","relpermalink":"/publication/wu2020investigating/","section":"publication","summary":"The phenomenon of increasing accidents caused by reduced vigilance does exist. In the future, the high accuracy of vigilance estimation will play a significant role in public transportation safety. We propose a multimodal regression network that consists of multichannel deep autoencoders with subnetwork neurons (MCDAEsn). After we define two thresholds of ``0.35'' and ``0.70'' from the percentage of eye closure, the output values are in the continuous range of 0-0.35, 0.36-0.70, and 0.71-1 representing the awake state, the tired state, and the drowsy state, respectively. To verify the efficiency of our strategy, we first applied the proposed approach to a single modality. Then, for the multimodality, since the complementary information between forehead electrooculography and electroencephalography features, we found the performance of the proposed approach using features fusion significantly improved, demonstrating the effectiveness and efficiency of our method.","tags":[],"title":"Investigating EEG-based functional connectivity patterns for multimodal emotion recognition","type":"publication"},{"authors":["Junwu Weng","Xudong Jiang","**Wei-Long Zheng**","Junsong Yuan"],"categories":null,"content":"","date":1582732800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1582732800,"objectID":"664722a1f0147ca9e6fd91c217d13e02","permalink":"https://weilongzheng.github.io/publication/weng2020early/","publishdate":"2020-02-27T00:00:00+08:00","relpermalink":"/publication/weng2020early/","section":"publication","summary":"The goal of early action recognition is to predict action label when the sequence is partially observed. The existing methods treat the early action recognition task as sequential classification problems on different observation ratios of an action sequence. Since these models are trained by differentiating positive category from all negative classes, the diverse information of different negative categories is ignored, which we believe can be collected to help improve the recognition performance. In this paper, we step towards to a new direction by introducing category exclusion to early action recognition. We model the exclusion as a mask operation on the classification probability output of a pre-trained early action recognition classifier. Specifically, we use policy-based reinforcement learning to train an agent. The agent generates a series of binary masks to exclude interfering negative categories during action execution and hence help improve the recognition accuracy. The proposed method is evaluated on three benchmark recognition datasets, NTU-RGBD, First-Person Hand Action, as well as UCF-101. The proposed method enhances the recognition accuracy consistently over all different observation ratios on the three datasets, where the accuracy improvements on the early stages are especially significant.","tags":[],"title":"Early Action Recognition with Category Exclusion using Policy-based Reinforcement Learning","type":"publication"},{"authors":["Amorim, Edilberto","Marcos Firme","**Wei-Long Zheng**","Kenneth Shelton","Oluwaseun Johnson-Akeju","Gaston Cudemus","Yuval Raz","M. Brandon Westover"],"categories":null,"content":"","date":1579017600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1579017600,"objectID":"e594e2a55a29f423ac8173585557dae7","permalink":"https://weilongzheng.github.io/publication/amorim2020767/","publishdate":"2020-01-15T00:00:00+08:00","relpermalink":"/publication/amorim2020767/","section":"publication","summary":"","tags":[],"title":"Epileptiform Abnormalities are Associated with Increased Mortality in Adult ECMO Patients","type":"publication"},{"authors":["**Wei-Long Zheng**","Jennifer Kim","Sahar Zafar","Eric Rosenthal","M. Brandon Westover"],"categories":null,"content":"","date":1579017600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1579017600,"objectID":"52dafd4be81273bedb60e3d29fabe7ec","permalink":"https://weilongzheng.github.io/publication/zheng2020760/","publishdate":"2020-01-15T00:00:00+08:00","relpermalink":"/publication/zheng2020760/","section":"publication","summary":"","tags":[],"title":"Machine Learning Model of EEG Trends Predicts Delayed Cerebral Ischemia Post-subarachnoid Hemorrhage","type":"publication"},{"authors":["Bo-Qun Ma","He Li","**Wei-Long Zheng**","Bao-Liang Lu"],"categories":null,"content":"","date":1575820800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1575820800,"objectID":"c2e717d0ec1fe28654d5ad656d31aa62","permalink":"https://weilongzheng.github.io/publication/ma2019reducing/","publishdate":"2019-12-09T00:00:00+08:00","relpermalink":"/publication/ma2019reducing/","section":"publication","summary":"","tags":[],"title":"Reducing the Subject Variability of EEG Signals with Adversarial Domain Generalization","type":"publication"},{"authors":["Jiaxin Ma","Hao Tang","**Wei-Long Zheng**","Bao-Liang Lu"],"categories":null,"content":"","date":1571673600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1571673600,"objectID":"3cb85efcc287e8e8dcb54084796cf3d0","permalink":"https://weilongzheng.github.io/publication/ma2019emotion/","publishdate":"2019-10-22T00:00:00+08:00","relpermalink":"/publication/ma2019emotion/","section":"publication","summary":"","tags":[],"title":"Emotion Recognition using Multimodal Residual LSTM Network","type":"publication"},{"authors":null,"categories":null,"content":"","date":1569859200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1569859200,"objectID":"1ce2dde4da6b4ea237172215f7bb2977","permalink":"https://weilongzheng.github.io/project/dci/","publishdate":"2019-10-01T00:00:00+08:00","relpermalink":"/project/dci/","section":"project","summary":"Predict delayed cerebral ischemia after subarachnoid hemorrhage with quantitative EEG.","tags":[],"title":"Delayed Cerebral Ischemia Prediction","type":"project"},{"authors":["**Wei-Long Zheng**","Haoqi Sun","Oluwaseun Akeju","M Brandon Westover"],"categories":null,"content":"","date":1569168000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1569168000,"objectID":"fcc7267ba91f9f7d152da54d9c9d38cd","permalink":"https://weilongzheng.github.io/publication/zheng2019adaptive/","publishdate":"2019-09-23T00:00:00+08:00","relpermalink":"/publication/zheng2019adaptive/","section":"publication","summary":"Sedative medications are routinely administered to provide comfort and facilitate clinical care in critically ill ICU patients. Prior work shows that brain monitoring using electroencephalography (EEG) to track sedation levels may help medical personnel to optimize drug dosing and avoid the adverse effects of oversedation and undersedation. However, the performance of sedation monitoring methods proposed to date deal poorly with individual variability across patients, leading to inconsistent performance. To address this challenge we develop an online learning approach based on Adaptive Regularization of Weight Vectors (AROW). Our approach adaptively updates a sedation level prediction algorithm under a continuously evolving data distribution. The prediction model is gradually calibrated for individual patients in response to EEG observations and routine clinical assessments over time. The evaluations are performed on a population of 172 sedated ICU patients whose sedation levels were assessed using the Richmond Agitation-Sedation Scale (scores between -5 = comatose and 0 = awake). The proposed adaptive model achieves better performance than the same model without adaptation (average accuracies with tolerance of one level difference: 68.76% vs. 61.10%). Moreover, our approach is shown to be robust to sudden changes caused by label noise. Medication administrations have different effects on model performance. We find that the model performs best in patients receiving only propofol, compared to patients receiving no sedation or multiple simultaneous sedative medications. ","tags":[],"title":"Adaptive Sedation Monitoring from EEG in ICU Patients with Online Learning","type":"publication"},{"authors":["Haoqi Sun","Eyal Kimchi","Oluwaseun Akeju","Sunil B. Nagaraj","Lauren M. McClain","David W. Zhou","Emily Boyle","**Wei-Long Zheng**","Wendong Ge","M. Brandon Westover"],"categories":null,"content":"","date":1567958400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1567958400,"objectID":"4ff0efd99200dc8760c3d8cd1930955d","permalink":"https://weilongzheng.github.io/publication/sun2019automated/","publishdate":"2019-09-09T00:00:00+08:00","relpermalink":"/publication/sun2019automated/","section":"publication","summary":"Over- and under-sedation are common in the ICU, and contribute to poor ICU outcomes including delirium. Behavioral assessments, such as Richmond Agitation-Sedation Scale (RASS) for monitoring levels of sedation and Confusion Assessment Method for the ICU (CAM-ICU) for detecting signs of delirium, are often used. As an alternative, brain monitoring with electroencephalography (EEG) has been proposed in the operating room, but is challenging to implement in ICU due to the differences between critical illness and elective surgery, as well as the duration of sedation. Here we present a deep learning model based on a combination of convolutional and recurrent neural networks that automatically tracks both the level of consciousness and delirium using frontal EEG signals in the ICU. For level of consciousness, the system achieves a median accuracy of 70% when allowing prediction to be within one RASS level difference across all patients, which is comparable or higher than the median technician–nurse agreement at 59%. For delirium, the system achieves an AUC of 0.80 with 69% sensitivity and 83% specificity at the optimal operating point. The results show it is feasible to continuously track level of consciousness and delirium in the ICU.","tags":[],"title":"Automated tracking of level of consciousness and delirium in critical illness using deep learning","type":"publication"},{"authors":["Wei Liu","Jie-Lin Qiu","**Wei-Long Zheng**","Bao-Liang Lu"],"categories":null,"content":"","date":1565625600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1565625600,"objectID":"3714da5edd6bdfd3daf9f5877d9db265","permalink":"https://weilongzheng.github.io/publication/liu2019multimodal/","publishdate":"2019-08-13T00:00:00+08:00","relpermalink":"/publication/liu2019multimodal/","section":"publication","summary":"","tags":[],"title":"Multimodal Emotion Recognition Using Deep Canonical Correlation Analysis","type":"publication"},{"authors":["Tian-Hao Li","Wei Liu","**Wei-Long Zheng**","Bao-Liang Lu"],"categories":null,"content":"","date":1558281600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1558281600,"objectID":"4f632cd53d35cd6a17aed3506630ef38","permalink":"https://weilongzheng.github.io/publication/li2019classification/","publishdate":"2019-05-20T00:00:00+08:00","relpermalink":"/publication/li2019classification/","section":"publication","summary":"","tags":[],"title":"Classification of five emotions from EEG and eye movement signals: Discrimination ability and stability over time","type":"publication"},{"authors":["Li-Ming Zhao","Rui Li","Wei-Long Zheng","Bao-Liang Lu"],"categories":null,"content":"","date":1558281600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1558281600,"objectID":"d7c1ee1ef830ab18bac028b9c2783b34","permalink":"https://weilongzheng.github.io/publication/zhao2019classification/","publishdate":"2019-05-20T00:00:00+08:00","relpermalink":"/publication/zhao2019classification/","section":"publication","summary":"","tags":[],"title":"Classification of five emotions from EEG and eye movement signals: complementary representation properties","type":"publication"},{"authors":["Xun Wu","**Wei-Long Zheng**","Bao-Liang Lu"],"categories":null,"content":"","date":1558281600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1558281600,"objectID":"2899c2db092e69e0ab2ea11bb658a1f2","permalink":"https://weilongzheng.github.io/publication/wu2019identifying/","publishdate":"2019-05-20T00:00:00+08:00","relpermalink":"/publication/wu2019identifying/","section":"publication","summary":"","tags":[],"title":"Identifying Functional Brain Connectivity Patterns for EEG-Based Emotion Recognition","type":"publication"},{"authors":["**Wei-Long Zheng**","Kunpeng Gao","Gang Li","Wei Liu","Chao Liu","Jing-Quan Liu","Guoxing Wang","Bao-Liang Lu"],"categories":null,"content":"","date":1548000000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1548000000,"objectID":"250b1948baf63320168d918e8550e331","permalink":"https://weilongzheng.github.io/publication/zheng2019vigilance/","publishdate":"2019-01-21T00:00:00+08:00","relpermalink":"/publication/zheng2019vigilance/","section":"publication","summary":"Vigilance decrement in driving tasks has been reported to be a major factor in fatal accidents and could severely endanger public transportation safety. However, efficient approaches for estimating vigilance in real driving environment are still lacking. In this paper, we propose a novel approach for implementing continuous vigilance estimation using forehead electrooculograms (EOGs) acquired by wearable dry electrodes in both simulated and real driving environments. To improve the feasibility of this approach for real-world applications, a forehead EOG-based electrode placement with only four electrodes is designed. Flexible dry electrodes and an acquisition board are integrated as a wearable device for recording EOGs. Twenty and ten subjects participated in the simulated and real-world driving environment experiments, respectively. Accurate eye movement parameters from eye-tracking glasses are extracted to calculate the PERCLOS index for vigilance annotation. This is because the vigilance state is a temporally dynamic process, and a continuous conditional random field and a continuous conditional neural field are introduced to construct more accurate vigilance estimation models. To evaluate the efficiency of our system, systematic experiments are performed in real scenarios under various illumination and weather conditions following laboratory simulations as preliminary studies. The experimental results demonstrate that the wearable dry electrode prototype, which has a relatively comfortable forehead setup, can efficiently capture vigilance dynamics. The best mean correlation coefficients achieved by our proposed approach are 71.18% and 66.20% in laboratory simulations and real-world driving environments, respectively. The cross-environment experiments are performed to evaluate the simulated-to-real generalization and a best mean correlation coefficient of 53.96% is achieved.","tags":[],"title":"Vigilance Estimation Using a Wearable EOG Device in Real Driving Environment","type":"publication"},{"authors":["Wei Wu","Q. M. Jonathan Wu","Wei Sun","Yimin Yang","Xiaofang Yuan","**Wei-Long Zheng**","Bao-Liang Lu"],"categories":null,"content":"","date":1545321600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1545321600,"objectID":"0380d1445d909dc0f0e2a02bab0fff60","permalink":"https://weilongzheng.github.io/publication/wu2018regression/","publishdate":"2018-12-21T00:00:00+08:00","relpermalink":"/publication/wu2018regression/","section":"publication","summary":"","tags":[],"title":"A regression method with subnetwork neurons for vigilance estimation using EOG and EEG","type":"publication"},{"authors":["Li-Ming Zhao","Xin-Wei Li","**Wei-Long Zheng**","Bao-Liang Lu"],"categories":null,"content":"","date":1542384000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1542384000,"objectID":"4a049642ac4e258b34d0c816a64c42cd","permalink":"https://weilongzheng.github.io/publication/zhao2018active/","publishdate":"2018-11-17T00:00:00+08:00","relpermalink":"/publication/zhao2018active/","section":"publication","summary":"","tags":[],"title":"Active Feedback Framework with Scan-Path Clustering for Deep Affective Models","type":"publication"},{"authors":["He Li","Yi-Ming Jin","**Wei-Long Zheng**","Bao-Liang Lu"],"categories":null,"content":"","date":1542384000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1542384000,"objectID":"c11fcf8651629438c7835600f298c644","permalink":"https://weilongzheng.github.io/publication/li2018cross/","publishdate":"2018-11-17T00:00:00+08:00","relpermalink":"/publication/li2018cross/","section":"publication","summary":"","tags":[],"title":"Cross-Subject Emotion Recognition Using Deep Adaptation Networks","type":"publication"},{"authors":["Yun Luo","Si-Yang Zhang","**Wei-Long Zheng**","Bao-Liang Lu"],"categories":null,"content":"","date":1542384000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1542384000,"objectID":"22e15b9d19e368a93d17e03273b63a26","permalink":"https://weilongzheng.github.io/publication/luo2018wgan/","publishdate":"2018-11-17T00:00:00+08:00","relpermalink":"/publication/luo2018wgan/","section":"publication","summary":"","tags":[],"title":"WGAN Domain Adaptation for EEG-Based Emotion Recognition","type":"publication"},{"authors":null,"categories":null,"content":"","date":1540569600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1540569600,"objectID":"591df82f86ed495bafe07ffeaee72ed9","permalink":"https://weilongzheng.github.io/project/icu/","publishdate":"2018-10-27T00:00:00+08:00","relpermalink":"/project/icu/","section":"project","summary":"Time series signal analysis and machine learning to improve clinical healthcare.","tags":[],"title":"Clinical Healthcare","type":"project"},{"authors":null,"categories":null,"content":"","date":1540569600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1540569600,"objectID":"f3666a831e5f343d86b70ffd571d7209","permalink":"https://weilongzheng.github.io/project/coma/","publishdate":"2018-10-27T00:00:00+08:00","relpermalink":"/project/coma/","section":"project","summary":"Investigate the relationship between various EEG patterns and coma outcomes for patients after cardiac arrest.","tags":[],"title":"Coma Prognostication","type":"project"},{"authors":["Changde Du","Changying Du","Hao Wang","Jinpeng Li","**Wei-Long Zheng**","Bao-Liang Lu","Huiguang He"],"categories":null,"content":"","date":1540137600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1540137600,"objectID":"dcd00041ab97443227c8c494b7648063","permalink":"https://weilongzheng.github.io/publication/du2018semi/","publishdate":"2018-10-22T00:00:00+08:00","relpermalink":"/publication/du2018semi/","section":"publication","summary":"","tags":[],"title":"Semi-supervised Deep Generative Modelling of Incomplete Multi-Modality Emotional Data","type":"publication"},{"authors":["He Li","**Wei-Long Zheng**","Bao-Liang Lu"],"categories":null,"content":"","date":1539532800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1539532800,"objectID":"443aaec08087a843999549997085191a","permalink":"https://weilongzheng.github.io/publication/li2018multimodal/","publishdate":"2018-10-15T00:00:00+08:00","relpermalink":"/publication/li2018multimodal/","section":"publication","summary":"","tags":[],"title":"Multimodal Vigilance Estimation with Adversarial Domain Adaptation Networks","type":"publication"},{"authors":["Jia-Jun Tong","Yun Luo","Bo-Qun Ma","**Wei-Long Zheng**","Bao-Liang Lu","Xiao-Qi Song","Shi-Wei Ma"],"categories":null,"content":"","date":1539532800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1539532800,"objectID":"5faa0772b9d939f816ae4323f4bc04c6","permalink":"https://weilongzheng.github.io/publication/tong2018sleep/","publishdate":"2018-10-15T00:00:00+08:00","relpermalink":"/publication/tong2018sleep/","section":"publication","summary":"","tags":[],"title":"Sleep Quality Estimation with Adversarial Domain Adaptation: From Laboratory to Real Scenario","type":"publication"},{"authors":["**Wei-Long Zheng**"],"categories":null,"content":"","date":1529856000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1529856000,"objectID":"20169f5cc4a3d65d11f36288ff375063","permalink":"https://weilongzheng.github.io/publication/zheng2018thesis/","publishdate":"2018-06-25T00:00:00+08:00","relpermalink":"/publication/zheng2018thesis/","section":"publication","summary":"","tags":[],"title":"Affective Brain-Computer Interactions","type":"publication"},{"authors":null,"categories":null,"content":"","date":1524758400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1524758400,"objectID":"dd6c15798e78e0ebec8824c52ba3c9aa","permalink":"https://weilongzheng.github.io/datasets/seed-iv/","publishdate":"2018-04-27T00:00:00+08:00","relpermalink":"/datasets/seed-iv/","section":"datasets","summary":"SJTU Emotion EEG Dataset (SEED-IV) of four emotions: happy, sad, fear, and neutral.","tags":[],"title":"SEED-IV","type":"datasets"},{"authors":["**Wei-Long Zheng**","Wei Liu","Yifei Lu","Bao-Liang Lu","Andrzej Cichocki"],"categories":null,"content":"","date":1518019200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1518019200,"objectID":"d23329cafc6af38e7e8a4cbb99958484","permalink":"https://weilongzheng.github.io/publication/zheng2018emotionmeter/","publishdate":"2018-02-08T00:00:00+08:00","relpermalink":"/publication/zheng2018emotionmeter/","section":"publication","summary":"In this paper, we present a multimodal emotion recognition framework called EmotionMeter that combines brain waves and eye movements. To increase the feasibility and wearability of EmotionMeter in real-world applications, we design a six-electrode placement above the ears to collect electroencephalography (EEG) signals. We combine EEG and eye movements for integrating the internal cognitive states and external subconscious behaviors of users to improve the recognition accuracy of EmotionMeter . The experimental results demonstrate that modality fusion with multimodal deep neural networks can significantly enhance the performance compared with a single modality, and the best mean accuracy of 85.11% is achieved for four emotions (happy, sad, fear, and neutral). We explore the complementary characteristics of EEG and eye movements for their representational capacities and identify that EEG has the advantage of classifying happy emotion, whereas eye movements outperform EEG in recognizing fear emotion. To investigate the stability of EmotionMeter over time, each subject performs the experiments three times on different days. EmotionMeter obtains a mean recognition accuracy of 72.39% across sessions with the six-electrode EEG and eye movement features. These experimental results demonstrate the effectiveness of EmotionMeter within and between sessions.","tags":[],"title":"Emotionmeter: A multimodal framework for recognizing human emotions","type":"publication"},{"authors":["Yi-Ming Jin","Yu-Dong Luo","**Wei-Long Zheng**","Bao-Liang Lu"],"categories":null,"content":"","date":1512662400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1512662400,"objectID":"7af7337bc4b9f7d3e59d80c4a46d6cc1","permalink":"https://weilongzheng.github.io/publication/jin2017eeg/","publishdate":"2017-12-08T00:00:00+08:00","relpermalink":"/publication/jin2017eeg/","section":"publication","summary":"","tags":[],"title":"EEG-based emotion recognition using domain adaptation network","type":"publication"},{"authors":["Xing-Zan Zhang","**Wei-Long Zheng**","Bao-Liang Lu"],"categories":null,"content":"","date":1508774400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1508774400,"objectID":"f6525c85c184007890a41a554ee0dc05","permalink":"https://weilongzheng.github.io/publication/zhang2017eeg/","publishdate":"2017-10-24T00:00:00+08:00","relpermalink":"/publication/zhang2017eeg/","section":"publication","summary":"","tags":[],"title":"EEG-based sleep quality evaluation with deep transfer learning","type":"publication"},{"authors":["Wei-Ye Zhao","Sheng Fang","Ting Ji","Qian Ji","**Wei-Long Zheng**","Bao-Liang Lu"],"categories":null,"content":"","date":1508774400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1508774400,"objectID":"6b1b143a9a9c630bdf7d6005f14dceda","permalink":"https://weilongzheng.github.io/publication/zhao2017emotion/","publishdate":"2017-10-24T00:00:00+08:00","relpermalink":"/publication/zhao2017emotion/","section":"publication","summary":"","tags":[],"title":"Emotion Annotation Using Hierarchical Aligned Cluster Analysis","type":"publication"},{"authors":["Xue Yan","**Wei-Long Zheng**","Wei Liu","Bao-Liang Lu"],"categories":null,"content":"","date":1508774400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1508774400,"objectID":"3b47b6e3f2d746dcd32c9789eccb4e7c","permalink":"https://weilongzheng.github.io/publication/yan2017identifying/","publishdate":"2017-10-24T00:00:00+08:00","relpermalink":"/publication/yan2017identifying/","section":"publication","summary":"","tags":[],"title":"Identifying Gender Differences in Multimodal Emotion Recognition Using Bimodal Deep AutoEncoder","type":"publication"},{"authors":["Xue Yan","**Wei-Long Zheng**","Wei Liu","Bao-Liang Lu"],"categories":null,"content":"","date":1508774400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1508774400,"objectID":"2b8cdf6a7153eaca91e919807b9c0547","permalink":"https://weilongzheng.github.io/publication/yan2017investigating/","publishdate":"2017-10-24T00:00:00+08:00","relpermalink":"/publication/yan2017investigating/","section":"publication","summary":"","tags":[],"title":"Investigating gender differences of brain areas in emotion recognition using LSTM neural network","type":"publication"},{"authors":["Hao Tang","Wei Liu","**Wei-Long Zheng**","Bao-Liang Lu"],"categories":null,"content":"","date":1508774400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1508774400,"objectID":"d1f9cd84bdd087766ad867a161171041","permalink":"https://weilongzheng.github.io/publication/tang2017multimodal/","publishdate":"2017-10-24T00:00:00+08:00","relpermalink":"/publication/tang2017multimodal/","section":"publication","summary":"","tags":[],"title":"Multimodal emotion recognition using deep neural networks","type":"publication"},{"authors":["Zhen-Feng Shi","Chang Zhou","**Wei-Long Zheng**","Bao-Liang Lu"],"categories":null,"content":"","date":1502726400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1502726400,"objectID":"6c07d46e48918f45df383c2bc7bf0b7f","permalink":"https://weilongzheng.github.io/publication/shi2017attention/","publishdate":"2017-08-15T00:00:00+08:00","relpermalink":"/publication/shi2017attention/","section":"publication","summary":"","tags":[],"title":"Attention evaluation with eye tracking glasses for EEG-based emotion recognition","type":"publication"},{"authors":["Li-Huan Du","Wei Liu","**Wei-Long Zheng**","Bao-Liang Lu"],"categories":null,"content":"","date":1502726400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1502726400,"objectID":"b5bc1eb13a0d84240490f06d4d37b0b9","permalink":"https://weilongzheng.github.io/publication/du2017detecting/","publishdate":"2017-08-15T00:00:00+08:00","relpermalink":"/publication/du2017detecting/","section":"publication","summary":"","tags":[],"title":"Detecting driving fatigue with multimodal deep learning","type":"publication"},{"authors":["Si-Yuan Wu","Moritz Schaefer","**Wei-Long Zheng**","Bao-Liang Lu","Hiroshi Yokoi"],"categories":null,"content":"","date":1502726400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1502726400,"objectID":"cf2008747fcc2591d36401f636ad3123","permalink":"https://weilongzheng.github.io/publication/wu2017neural/","publishdate":"2017-08-15T00:00:00+08:00","relpermalink":"/publication/wu2017neural/","section":"publication","summary":"","tags":[],"title":"Neural patterns between Chinese and Germans for EEG-based emotion recognition","type":"publication"},{"authors":["**Wei-Long Zheng**","Jia-Yi Zhu","Bao-Liang Lu"],"categories":null,"content":"","date":1496592000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1496592000,"objectID":"71d71fdce9b0183960e5f7421be07afa","permalink":"https://weilongzheng.github.io/publication/zheng2017identifying/","publishdate":"2017-06-05T00:00:00+08:00","relpermalink":"/publication/zheng2017identifying/","section":"publication","summary":"In this paper, we investigate stable patterns of electroencephalogram (EEG) over time for emotion recognition using a machine learning approach. Up to now, various findings of activated patterns associated with different emotions have been reported. However, their stability over time has not been fully investigated yet. In this paper, we focus on identifying EEG stability in emotion recognition. We systematically evaluate the performance of various popular feature extraction, feature selection, feature smoothing and pattern classification methods with the DEAP dataset and a newly developed dataset called SEED for this study. Discriminative Graph regularized Extreme Learning Machine with differential entropy features achieves the best average accuracies of 69.67% and 91.07% on the DEAP and SEED datasets, respectively. The experimental results indicate that stable patterns exhibit consistency across sessions; the lateral temporal areas activate more for positive emotions than negative emotions in beta and gamma bands; the neural patterns of neutral emotions have higher alpha responses at parietal and occipital sites; and for negative emotions, the neural patterns have significant higher delta responses at parietal and occipital sites and higher gamma responses at prefrontal sites. The performance of our emotion recognition models shows that the neural patterns are relatively stable within and between sessions.","tags":[],"title":"Identifying stable patterns over time for emotion recognition from EEG","type":"publication"},{"authors":null,"categories":null,"content":"","date":1493222400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1493222400,"objectID":"51ffca6fccc96e29e36d3d04c922b7d9","permalink":"https://weilongzheng.github.io/datasets/seed-vig/","publishdate":"2017-04-27T00:00:00+08:00","relpermalink":"/datasets/seed-vig/","section":"datasets","summary":"A Multimodal Dataset with EEG and Forehead EOG for Vigilance Estimation (SEED-VIG).","tags":[],"title":"SEED-VIG","type":"datasets"},{"authors":null,"categories":null,"content":"","date":1493222400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1493222400,"objectID":"c995a9e5e77971e4dba2bb0ea51e1730","permalink":"https://weilongzheng.github.io/project/vigilance/","publishdate":"2017-04-27T00:00:00+08:00","relpermalink":"/project/vigilance/","section":"project","summary":"Multimodal Vigilance Estimation using EEG and EOG: From Simulated To Real Environments.","tags":[],"title":"Vigilance Estimation","type":"project"},{"authors":["Changde Du","Changying Du","Jinpeng Li","**Wei-long Zheng**","Bao-liang Lu","Huiguang He"],"categories":null,"content":"","date":1493049600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1493049600,"objectID":"1550711a7f06977640c9ef818b106263","permalink":"https://weilongzheng.github.io/publication/du2017semi/","publishdate":"2017-04-25T00:00:00+08:00","relpermalink":"/publication/du2017semi/","section":"publication","summary":"","tags":[],"title":"Semi-supervised Bayesian Deep Multi-modal Emotion Recognition","type":"publication"},{"authors":["Yimin Yang","Q. M. Jonathan Wu","**Wei-Long Zheng**","Bao-Liang Lu"],"categories":null,"content":"","date":1490025600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1490025600,"objectID":"d3083ec148404c7a2d0e4d5578328cc6","permalink":"https://weilongzheng.github.io/publication/yang2018eeg/","publishdate":"2017-03-21T00:00:00+08:00","relpermalink":"/publication/yang2018eeg/","section":"publication","summary":"","tags":[],"title":"EEG-based emotion recognition using hierarchical network with subnetwork nodes","type":"publication"},{"authors":["**Wei-Long Zheng**","Bao-Liang Lu"],"categories":null,"content":"","date":1487692800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1487692800,"objectID":"f453b5326518ac5812d2c2565488c100","permalink":"https://weilongzheng.github.io/publication/zheng2017multimodal/","publishdate":"2017-02-22T00:00:00+08:00","relpermalink":"/publication/zheng2017multimodal/","section":"publication","summary":"Objective. Covert aspects of ongoing user mental states provide key context information for user-aware human computer interactions. In this paper, we focus on the problem of estimating the vigilance of users using EEG and EOG signals. Approach. The PERCLOS index as vigilance annotation is obtained from eye tracking glasses. To improve the feasibility and wearability of vigilance estimation devices for real-world applications, we adopt a novel electrode placement for forehead EOG and extract various eye movement features, which contain the principal information of traditional EOG. We explore the effects of EEG from different brain areas and combine EEG and forehead EOG to leverage their complementary characteristics for vigilance estimation. Considering that the vigilance of users is a dynamic changing process because the intrinsic mental states of users involve temporal evolution, we introduce continuous conditional neural field and continuous conditional random field models to capture dynamic temporal dependency. Main results. We propose a multimodal approach to estimating vigilance by combining EEG and forehead EOG and incorporating the temporal dependency of vigilance into model training. The experimental results demonstrate that modality fusion can improve the performance compared with a single modality, EOG and EEG contain complementary information for vigilance estimation, and the temporal dependency-based models can enhance the performance of vigilance estimation. From the experimental results, we observe that theta and alpha frequency activities are increased, while gamma frequency activities are decreased in drowsy states in contrast to awake states. Significance. The forehead setup allows for the simultaneous collection of EEG and EOG and achieves comparative ","tags":[],"title":"A multimodal approach to estimating vigilance using EEG and forehead EOG","type":"publication"},{"authors":["Xue-Qin Huo","**Wei-Long Zheng**","Bao-Liang Lu"],"categories":null,"content":"","date":1478102400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1478102400,"objectID":"918c552cb26866172f706b8fcea18255","permalink":"https://weilongzheng.github.io/publication/huo2016driving/","publishdate":"2016-11-03T00:00:00+08:00","relpermalink":"/publication/huo2016driving/","section":"publication","summary":"","tags":[],"title":"Driving fatigue detection with fusion of EEG and forehead EOG","type":"publication"},{"authors":["Li-Li Wang","**Wei-Long Zheng**","Hai-Wei Ma","Bao-Liang Lu"],"categories":null,"content":"","date":1478102400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1478102400,"objectID":"4adcb4a652c37a6c01009760f49bfa91","permalink":"https://weilongzheng.github.io/publication/wang2016measuring/","publishdate":"2016-11-03T00:00:00+08:00","relpermalink":"/publication/wang2016measuring/","section":"publication","summary":"","tags":[],"title":"Measuring sleep quality from EEG with machine learning approaches","type":"publication"},{"authors":["Nan Zhang","**Wei-Long Zheng**","Wei Liu","Bao-Liang Lu"],"categories":null,"content":"","date":1475164800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1475164800,"objectID":"235f75c9b48652f48068e70dda9108bc","permalink":"https://weilongzheng.github.io/publication/zhang2016continuous/","publishdate":"2016-09-30T00:00:00+08:00","relpermalink":"/publication/zhang2016continuous/","section":"publication","summary":"","tags":[],"title":"Continuous vigilance estimation using LSTM neural networks","type":"publication"},{"authors":["Wei Liu","**Wei-Long Zheng**","Bao-Liang Lu"],"categories":null,"content":"","date":1475164800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1475164800,"objectID":"25e22759e400adbb6685c7a20167d7fb","permalink":"https://weilongzheng.github.io/publication/liu2016emotion/","publishdate":"2016-09-30T00:00:00+08:00","relpermalink":"/publication/liu2016emotion/","section":"publication","summary":"","tags":[],"title":"Emotion recognition using multimodal deep learning","type":"publication"},{"authors":["**Wei-Long Zheng**","Bao-Liang Lu"],"categories":null,"content":"","date":1467993600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1467993600,"objectID":"99fc2761ca6994eae6ae92a0b4b3602b","permalink":"https://weilongzheng.github.io/publication/zheng2016personalizing/","publishdate":"2016-07-09T00:00:00+08:00","relpermalink":"/publication/zheng2016personalizing/","section":"publication","summary":"Individual differences across subjects and nonstationary characteristic of electroencephalography (EEG) limit the generalization of affective brain-computer interfaces in real-world applications. On the other hand, it is very time consuming and expensive to acquire a large number of subject-specific labeled data for learning subject-specific models. In this paper, we propose to build personalized EEG-based affective models without labeled target data using transfer learning techniques. We mainly explore two types of subject-to-subject transfer approaches. One is to exploit shared structure underlying source domain (source subject) and target domain (target subject). The other is to train multiple individual classifiers on source subjects and transfer knowledge about classifier parameters to target subjects, and its aim is to learn a regression function that maps the relationship between feature distribution and classifier parameters. We compare the performance of five different approaches on an EEG dataset for constructing an affective model with three affective states: positive, neutral, and negative. The experimental results demonstrate that our proposed subject transfer framework achieves the mean accuracy of 76.31% in comparison with a conventional generic classifier with 56.73% in average.","tags":[],"title":"Personalizing EEG-based affective models with transfer learning","type":"publication"},{"authors":null,"categories":null,"content":"","date":1461686400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461686400,"objectID":"6109bfd76c04dbc76005e7316a4dc31e","permalink":"https://weilongzheng.github.io/project/transfer/","publishdate":"2016-04-27T00:00:00+08:00","relpermalink":"/project/transfer/","section":"project","summary":"Transfer learning algorithms are used to tackle individual differences across subjects and sessions and non-stationary characteristics of EEG.","tags":[],"title":"Transfer Learning","type":"project"},{"authors":["Wei Liu","**Wei-Long Zheng**","Bao-Liang Lu"],"categories":null,"content":"","date":1456416000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1456416000,"objectID":"b222b7f62703a4eb51d60a27233a31d7","permalink":"https://weilongzheng.github.io/publication/liu2016multimodal/","publishdate":"2016-02-26T00:00:00+08:00","relpermalink":"/publication/liu2016multimodal/","section":"publication","summary":"","tags":[],"title":"Multimodal emotion recognition using multimodal deep learning","type":"publication"},{"authors":["**Wei-Long Zheng**","Shan-Chun Shen","Bao-Liang Lu"],"categories":null,"content":"","date":1455811200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1455811200,"objectID":"ca0ce6c6587dd1936684ca4087674c4c","permalink":"https://weilongzheng.github.io/publication/zheng2017online/","publishdate":"2016-02-19T00:00:00+08:00","relpermalink":"/publication/zheng2017online/","section":"publication","summary":"","tags":[],"title":"Online depth image-based object tracking with sparse representation and object detection","type":"publication"},{"authors":["Yong Peng","**Wei-Long Zheng**","Bao-Liang Lu"],"categories":null,"content":"","date":1453392000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1453392000,"objectID":"c28ca841cceda1538ea4b296695ffcdf","permalink":"https://weilongzheng.github.io/publication/peng2016unsupervised/","publishdate":"2016-01-22T00:00:00+08:00","relpermalink":"/publication/peng2016unsupervised/","section":"publication","summary":"","tags":[],"title":"An unsupervised discriminative extreme learning machine and its applications to data clustering","type":"publication"},{"authors":["Yong-Qi Zhang","**Wei-Long Zheng**","Bao-Liang Lu"],"categories":null,"content":"","date":1447776000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1447776000,"objectID":"23dff1784fcf9344d52b1ee60927dad0","permalink":"https://weilongzheng.github.io/publication/zhang2015transfer/","publishdate":"2015-11-18T00:00:00+08:00","relpermalink":"/publication/zhang2015transfer/","section":"publication","summary":"","tags":[],"title":"Transfer components between subjects for EEG-based driving fatigue detection","type":"publication"},{"authors":["**Wei-Long Zheng**","Yong-Qi Zhang","Jia-Yi Zhu","Bao-Liang Lu"],"categories":null,"content":"","date":1442764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1442764800,"objectID":"27413c56ada88828b5d4dc3fb7f6aa78","permalink":"https://weilongzheng.github.io/publication/zheng2015transfer/","publishdate":"2015-09-21T00:00:00+08:00","relpermalink":"/publication/zheng2015transfer/","section":"publication","summary":"","tags":[],"title":"Transfer components between subjects for EEG-based emotion recognition","type":"publication"},{"authors":["Yu-Fei Zhang","Xiang-Yu Gao","Jia-Yi Zhu","**Wei-Long Zheng**","Bao-Liang Lu"],"categories":null,"content":"","date":1435766400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1435766400,"objectID":"95193da73add2c552f8a606e2445db18","permalink":"https://weilongzheng.github.io/publication/zhang2015novel/","publishdate":"2015-07-02T00:00:00+08:00","relpermalink":"/publication/zhang2015novel/","section":"publication","summary":"","tags":[],"title":"A novel approach to driving fatigue detection using forehead EOG","type":"publication"},{"authors":["Xiang-Yu Gao","Yu-Fei Zhang","**Wei-Long Zheng**","Bao-Liang Lu"],"categories":null,"content":"","date":1435766400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1435766400,"objectID":"dde58e7a3b261f7df50aedbebfff7353","permalink":"https://weilongzheng.github.io/publication/gao2015evaluating/","publishdate":"2015-07-02T00:00:00+08:00","relpermalink":"/publication/gao2015evaluating/","section":"publication","summary":"","tags":[],"title":"Evaluating driving fatigue detection algorithms using eye tracking glasses","type":"publication"},{"authors":["**Wei-Long Zheng**","Hao-Tian Guo","Bao-Liang Lu"],"categories":null,"content":"","date":1435766400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1435766400,"objectID":"ec87daa93f3ce61d412afef32e91ea8e","permalink":"https://weilongzheng.github.io/publication/zheng2015revealing/","publishdate":"2015-07-02T00:00:00+08:00","relpermalink":"/publication/zheng2015revealing/","section":"publication","summary":"","tags":[],"title":"Revealing critical channels and frequency bands for emotion recognition from EEG with deep belief network","type":"publication"},{"authors":["Yifei Lu*","**Wei-Long Zheng***","Binbin Li","Bao-Liang Lu"],"categories":null,"content":"","date":1434988800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1434988800,"objectID":"25e48ce6f342e6e73b71877eacef54a1","permalink":"https://weilongzheng.github.io/publication/lu2015combining/","publishdate":"2015-06-23T00:00:00+08:00","relpermalink":"/publication/lu2015combining/","section":"publication","summary":"In this paper, we adopt a multimodal emotion recognition framework by combining eye movements and electroencephalography (EEG) to enhance emotion recognition. The main contributions of this paper are twofold. a) We investigate sixteen eye movements related to emotions and identify the intrinsic patterns of these eye movements for three emotional states: positive, neutral and negative. b) We examine various modality fusion strategies for integrating users external subconscious behaviors and internal cognitive states and reveal that the characteristics of eye movements and EEG are complementary to emotion recognition. Experiment results demonstrate that modality fusion could significantly improve emotion recognition accuracy in comparison with single modality. The best accuracy achieved by fuzzy integral fusion strategy is 87.59%, whereas the accuracies of solely using eye movements and EEG data are 77.80% and 78.51%, respectively.","tags":[],"title":"Combining eye movements and EEG to enhance emotion recognition","type":"publication"},{"authors":["**Wei-Long Zheng**","Roberto Santana","Bao-Liang Lu"],"categories":null,"content":"","date":1433606400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1433606400,"objectID":"02d88cb8c75601601ec038c4887aa191","permalink":"https://weilongzheng.github.io/publication/zheng2015comparison/","publishdate":"2015-06-07T00:00:00+08:00","relpermalink":"/publication/zheng2015comparison/","section":"publication","summary":"","tags":[],"title":"Comparison of classification methods for EEG-based emotion recognition","type":"publication"},{"authors":["Jia-Yi Zhu","**Wei-Long Zheng**","Bao-Liang Lu"],"categories":null,"content":"","date":1433606400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1433606400,"objectID":"785d5b2596ae538a34b5cf9088e9696e","permalink":"https://weilongzheng.github.io/publication/zhu2015cross/","publishdate":"2015-06-07T00:00:00+08:00","relpermalink":"/publication/zhu2015cross/","section":"publication","summary":"","tags":[],"title":"Cross-subject and cross-gender emotion classification from EEG","type":"publication"},{"authors":["**Wei-Long Zheng**","Bao-Liang Lu"],"categories":null,"content":"","date":1431014400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1431014400,"objectID":"a1d7c08597266fa724529bfbbb1b00e9","permalink":"https://weilongzheng.github.io/publication/zheng2015investigating/","publishdate":"2015-05-08T00:00:00+08:00","relpermalink":"/publication/zheng2015investigating/","section":"publication","summary":"To investigate critical frequency bands and channels, this paper introduces deep belief networks (DBNs) to constructing EEG-based emotion recognition models for three emotions: positive, neutral and negative. We develop an EEG dataset acquired from 15 subjects. Each subject performs the experiments twice at the interval of a few days. DBNs are trained with differential entropy features extracted from multichannel EEG data. We examine the weights of the trained DBNs and investigate the critical frequency bands and channels. Four different profiles of 4, 6, 9, and 12 channels are selected. The recognition accuracies of these four profiles are relatively stable with the best accuracy of 86.65%, which is even better than that of the original 62 channels. The critical frequency bands and channels determined by using the weights of trained DBNs are consistent with the existing observations. In addition, our experiment results show that neural signatures associated with different emotions do exist and they share commonality across sessions and individuals. We compare the performance of deep models with shallow models. The average accuracies of DBN, SVM, LR, and KNN are 86.08%, 83.99%, 82.70%, and 72.60%, respectively.","tags":[],"title":"Investigating critical frequency bands and channels for EEG-based emotion recognition with deep neural networks","type":"publication"},{"authors":null,"categories":null,"content":"","date":1430064000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1430064000,"objectID":"37df4810ed8142b64c74cf78f524a3c1","permalink":"https://weilongzheng.github.io/datasets/seed/","publishdate":"2015-04-27T00:00:00+08:00","relpermalink":"/datasets/seed/","section":"datasets","summary":"SJTU Emotion EEG Dataset (SEED) of three emotions: positive, neutral, and negative.","tags":[],"title":"SEED","type":"datasets"},{"authors":["Yong Peng","Jia-Yi Zhu","**Wei-Long Zheng**","Bao-Liang Lu"],"categories":null,"content":"","date":1415203200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1415203200,"objectID":"ecd31cac8f82b13d9ef0861032e1649c","permalink":"https://weilongzheng.github.io/publication/peng2014eeg/","publishdate":"2014-11-06T00:00:00+08:00","relpermalink":"/publication/peng2014eeg/","section":"publication","summary":"","tags":[],"title":"EEG-based emotion recognition with manifold regularized extreme learning machine","type":"publication"},{"authors":["**Wei-Long Zheng**","Bo-Nan Dong","Bao-Liang Lu"],"categories":null,"content":"","date":1415203200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1415203200,"objectID":"da7a32e53f966f422ab1e3aabbb680ba","permalink":"https://weilongzheng.github.io/publication/zheng2014multimodal/","publishdate":"2014-11-06T00:00:00+08:00","relpermalink":"/publication/zheng2014multimodal/","section":"publication","summary":"","tags":[],"title":"Multimodal emotion recognition using EEG and eye tracking data","type":"publication"},{"authors":["**Wei-Long Zheng**","Jia-Yi Zhu","Bao-Liang Lu"],"categories":null,"content":"","date":1415203200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1415203200,"objectID":"f151517e84f8e480a531850b972da6a6","permalink":"https://weilongzheng.github.io/publication/zheng2014multimodel2/","publishdate":"2014-11-06T00:00:00+08:00","relpermalink":"/publication/zheng2014multimodel2/","section":"publication","summary":"","tags":[],"title":"Multimodel emotion analysis in response to multimedia","type":"publication"},{"authors":["Shan-Chun Shen","**Wei-Long Zheng**","Bao-Liang Lu"],"categories":null,"content":"","date":1414944000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1414944000,"objectID":"ee34a639c311ddf551ee27fc529dfd20","permalink":"https://weilongzheng.github.io/publication/shen2014online/","publishdate":"2014-11-03T00:00:00+08:00","relpermalink":"/publication/shen2014online/","section":"publication","summary":"","tags":[],"title":"Online object tracking based on depth image with sparse coding","type":"publication"},{"authors":["**Wei-Long Zheng**","Jia-Yi Zhu","Yong Peng","Bao-Liang Lu"],"categories":null,"content":"","date":1410105600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1410105600,"objectID":"1d591023d16ddaa4366a64d8fb1e8bb5","permalink":"https://weilongzheng.github.io/publication/zheng2014eeg/","publishdate":"2014-09-08T00:00:00+08:00","relpermalink":"/publication/zheng2014eeg/","section":"publication","summary":"In recent years, there are many great successes in using deep architectures for unsupervised feature learning from data, especially for images and speech. In this paper, we introduce recent advanced deep learning models to classify two emotional categories (positive and negative) from EEG data. We train a deep belief network (DBN) with differential entropy features extracted from multichannel EEG as input. A hidden markov model (HMM) is integrated to accurately capture a more reliable emotional stage switching. We also compare the performance of the deep models to KNN, SVM and Graph regularized Extreme Learning Machine (GELM). The average accuracies of DBN-HMM, DBN, GELM, SVM, and KNN in our experiments are 87.62%, 86.91%, 85.67%, 84.08%, and 69.66%, respectively. Our experimental results show that the DBN and DBN-HMM models improve the accuracy of EEG-based emotion classification in comparison with the state-of-the-art methods.","tags":[],"title":"EEG-based emotion classification using deep belief networks","type":"publication"},{"authors":["Jia-Yi Zhu","**Wei-Long Zheng**","Ruo-Nan Duan","Yong Peng","Bao-Liang Lu"],"categories":null,"content":"","date":1409760000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1409760000,"objectID":"c65f9432a5228a4ef4c0bbf1286a1046","permalink":"https://weilongzheng.github.io/publication/zhu2014eeg/","publishdate":"2014-09-04T00:00:00+08:00","relpermalink":"/publication/zhu2014eeg/","section":"publication","summary":"","tags":[],"title":"EEG-based emotion recognition using discriminative graph regularized extreme learning machine","type":"publication"},{"authors":["Xuemin Zhu","**Wei-Long Zheng**","Bao-Liang Lu","Xiaoping Chen","Shanguang Chen","Chunhui Wang"],"categories":null,"content":"","date":1409760000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1409760000,"objectID":"fb22348673ae65c0a84a2128523dd7f3","permalink":"https://weilongzheng.github.io/publication/zhu2014eog/","publishdate":"2014-09-04T00:00:00+08:00","relpermalink":"/publication/zhu2014eog/","section":"publication","summary":"","tags":[],"title":"EOG-based drowsiness detection using convolutional neural networks","type":"publication"},{"authors":["Simin Zhao","Xiangming Xu","**Wei-Long Zheng**","Jianwen Ling"],"categories":null,"content":"","date":1338739200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1338739200,"objectID":"d7dc5f2b38bd1fd1b08bfb2ef1795aad","permalink":"https://weilongzheng.github.io/publication/zhao2012registration/","publishdate":"2012-06-04T00:00:00+08:00","relpermalink":"/publication/zhao2012registration/","section":"publication","summary":"","tags":[],"title":"Registration of depth image and color image based on Harris-SIFT","type":"publication"}]